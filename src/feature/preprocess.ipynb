{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes from Original DART API CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "bs = pd.read_csv('dart_bs.csv')\n",
    "cis = pd.read_csv('dart_cis.csv')\n",
    "cf = pd.read_csv('dart_cf.csv')\n",
    "incs = pd.read_csv('dart_incs.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs['label_en'] = bs['label_en'].str.lower()\n",
    "cis['label_en'] = cis['label_en'].str.lower()\n",
    "cf['label_en'] = cf['label_en'].str.lower()\n",
    "incs['label_en'] = incs['label_en'].str.lower()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Comprehensive Income Statement with Income Statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_with_incs = incs['corp'].unique()\n",
    "\n",
    "for corp in corp_with_incs: \n",
    "    right_index = cis[cis['corp'] == corp].index[-1] \n",
    "    \n",
    "    cis_left = cis.iloc[:right_index + 1]\n",
    "    cis_right  = cis.iloc[right_index + 1:] \n",
    "    \n",
    "    incs_rows = incs[incs['corp'] == corp]\n",
    "    \n",
    "    cis = pd.concat([cis_left, incs_rows, cis_right], ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis.to_csv('cis_updated.csv', encoding='utf-8-sig', index=False) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get KOSPI List from DART API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dart_fss as dart\n",
    "api_key='58b7a0538b393d6c96f7f93b31101d5f407c9d1d'\n",
    "dart.set_api_key(api_key=api_key)\n",
    "\n",
    "corp_list = dart.get_corp_list()\n",
    "kospi_list = corp_list.find_by_corp_name(corp_name='', market='Y')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA \n",
    "- 산업별로 그래프 \n",
    "\n",
    "- null값, 이상치, 분포, 산포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2018', '2019', '2020', '2021', '2022'] \n",
    "\n",
    "print(bs[years].isna().sum(), end=\"\\n\\n\")\n",
    "print(cis[years].isna().sum(), end=\"\\n\\n\")\n",
    "print(cf[years].isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USEFUL FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feature(df, prefix):\n",
    "    \n",
    "    years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "    for year in years:\n",
    "        original_column = f\"{prefix}_{year}\"\n",
    "        new_column = year\n",
    "        df.rename(columns={original_column: new_column}, inplace=True)\n",
    "    \n",
    "    final_df = pd.melt(df, id_vars=['corp'], value_vars=years, var_name='year', value_name=prefix)\n",
    "    \n",
    "    final_df = final_df.sort_values(by=['corp', 'year']).reset_index(drop=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def find_missing_corps(main_df, subset_df):\n",
    "    main_corp_unique = set(main_df['corp'].unique())\n",
    "    subset_corp_unique = set(subset_df['corp'].unique())\n",
    "\n",
    "    missing_corps = main_corp_unique - subset_corp_unique\n",
    "    \n",
    "    return missing_corps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_operation(cis, company_name, feature_name, feat1, feat2, operation, years=['2018', '2019', '2020', '2021', '2022']):\n",
    "    \n",
    "    feature_1 = cis.loc[(cis['label_en'] == feat1) & (cis['corp'] == company_name), years]\n",
    "    feature_2 = cis.loc[(cis['label_en'] == feat2) & (cis['corp'] == company_name), years]\n",
    "    \n",
    "    result_list = []\n",
    "    \n",
    "    for year in years:\n",
    "        values1 = feature_1[year].values\n",
    "        values2 = feature_2[year].values\n",
    "\n",
    "        if values1.size > 0 and values2.size > 0:\n",
    "            if operation == 'divide':\n",
    "                result = values1[0] / values2[0]\n",
    "            elif operation == 'add':\n",
    "                result = values1[0] + values2[0]\n",
    "            else:\n",
    "                result = np.nan\n",
    "        else:\n",
    "            result = np.nan\n",
    "        \n",
    "        result_list.append({'corp': company_name, 'year': year, feature_name: result})\n",
    "    \n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "operating_income = cis[cis['label_en'].isin((\n",
    "    'operating income(loss)', \n",
    "    'sales account', \n",
    "    'operating loss', \n",
    "    'operating income', \n",
    "    'operating profit', \n",
    "    'operating profit (loss)',\n",
    "    'operating profit(loss)',\n",
    "    'operating profits'\n",
    "))]\n",
    "\n",
    "operating_income = operating_income.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "find_missing_corps(cis, operating_income) \n",
    "\n",
    "feature_operating_income = process_feature(operating_income.copy(), 'operating_income') \n",
    "\n",
    "feature_operating_income = feature_operating_income.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LG유플러스', 'LX홀딩스', '대웅', '아이에이치큐', '카카오', '케이티스카이라이프'}"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "revenue_list = ['revenue(sales)', 'revenue', 'sales(revenue)', 'sales', 'sales of goods', 'net sales', 'sales income', 'sales account']\n",
    "\n",
    "revenue = cis[cis['label_en'].isin((\n",
    "    revenue_list\n",
    "))]\n",
    "\n",
    "revenue = revenue.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "feature_revenue = process_feature(revenue.copy(), 'revenue') \n",
    "\n",
    "find_missing_corps(cis, revenue) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue1 = feature_operation(cis, 'LG유플러스', 'revenue', 'operating income', 'operating expenses', 'divide')\n",
    "revenue2 = feature_operation(cis, 'LX홀딩스', 'revenue', 'operating income', 'operating expenses', 'divide')\n",
    "revenue3 = feature_operation(cis, '대웅', 'revenue', 'duddjqtndlr', 'selling general administrative expenses', 'add')\n",
    "revenue4 = feature_operation(cis, '아이에이치큐', 'revenue', 'gross profit', 'selling general administrative expenses', 'add')\n",
    "revenue5 = feature_operation(cis, '카카오', 'revenue', 'gross profit', 'selling general administrative expenses', 'add')\n",
    "revenue6 = feature_operation(cis, '케이티스카이라이프', 'revenue', 'operating revenues', 'operating expenses', 'add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue1 = feature_operation(cis, 'LG유플러스', 'revenue', 'operating income', 'operating expenses', 'divide', years)\n",
    "revenue2 = feature_operation(cis, 'LX홀딩스', 'revenue', 'operating income', 'operating expenses', 'divide', years)\n",
    "revenue3 = feature_operation(cis, '대웅', 'revenue', 'duddjqtndlr', 'selling general administrative expenses', 'add', years)\n",
    "revenue4 = feature_operation(cis, '아이에이치큐', 'revenue', 'gross profit', 'selling general administrative expenses', 'add', years)\n",
    "revenue5 = feature_operation(cis, '카카오', 'revenue', 'gross profit', 'selling general administrative expenses', 'add', years)\n",
    "revenue6 = feature_operation(cis, '케이티스카이라이프', 'revenue', 'operating revenues', 'operating expenses', 'add', years)\n",
    "\n",
    "for revenue in [revenue1, revenue2, revenue3, revenue4, revenue5, revenue6]: \n",
    "    feature_revenue = feature_revenue.append(revenue) \n",
    "\n",
    "feature_revenue = feature_revenue.reset_index(drop=True)\n",
    "\n",
    "feature_revenue = feature_revenue.drop_duplicates(subset=['corp', 'year'], keep='first')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'남해화학', '일진전기'}"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_income_list = ['profit', 'profit (loss)', 'profit(loss)', 'profit (loss) for the period', 'profit(loss) for the period', 'profit (loss) for the year',\n",
    "'loss (profit)', 'net income(loss)', 'net income', 'profit for the year', 'quarterly net income, attributable to', 'semiannual net profit',\n",
    "'net profit during thr current term', 'the year net profit(loss)', 'net profit', 'ifrs_profitloss', 'quarterly net profit', '- profit (loss)']\n",
    "\n",
    "net_income = cis[cis['label_en'].isin((\n",
    "    net_income_list\n",
    "))]\n",
    "\n",
    "net_income = net_income.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "net_income = process_feature(net_income.copy(), 'net_income')\n",
    "\n",
    "find_missing_corps(cis, net_income) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (cis['corp'] == '일진전기') & (cis['label_en'] == 'profit (loss), attributable to non-controlling interests')\n",
    "cis.loc[mask, '2018'] = 0\n",
    "cis.loc[mask, '2019'] = 0\n",
    "cis.loc[mask, '2020'] = 0\n",
    "cis.loc[mask, '2021'] = 0\n",
    "cis.loc[mask, '2022'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/qrlg6jnd1l5b_xdkq486q0zr0000gn/T/ipykernel_3034/2446638349.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  feature_net_income = net_income.append([net_income_1, net_income_2])\n"
     ]
    }
   ],
   "source": [
    "net_income_1 = feature_operation(cis, '남해화학', 'net_income', 'profit (loss), attributable to owners of parent', 'profit (loss), attributable to non-controlling interests', 'add', years)\n",
    "net_income_2 = feature_operation(cis, '일진전기', 'net_income', 'profit (loss), attributable to owners of parent', 'profit (loss), attributable to non-controlling interests', 'add', years)\n",
    "\n",
    "feature_net_income = net_income.append([net_income_1, net_income_2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Outstanding Shares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='58b7a0538b393d6c96f7f93b31101d5f407c9d1d'\n",
    "dart.set_api_key(api_key=api_key)\n",
    "\n",
    "corp_list = dart.get_corp_list()\n",
    "kospi_list = corp_list.find_by_corp_name(corp_name='', market='Y')\n",
    "\n",
    "successful_list = list(bs['corp'].unique())\n",
    "kospi_list = [comp.corp_name for comp in kospi_list]\n",
    "failed_list = [comp for comp in kospi_list if comp not in successful_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "corp_dict = {} \n",
    "\n",
    "kospi_list \n",
    "\n",
    "for comp in kospi_list: \n",
    "    corp_dict[comp.corp_name] = comp.corp_code \n",
    "\n",
    "for key in failed_list:\n",
    "    if key in corp_dict:\n",
    "        del corp_dict[key]\n",
    "\n",
    "url = 'https://opendart.fss.or.kr/api/stockTotqySttus.json'\n",
    "api_key = '58b7a0538b393d6c96f7f93b31101d5f407c9d1d'\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "results = []\n",
    "\n",
    "for corp_name, corp_code in corp_dict.items():\n",
    "    for year in years:\n",
    "        params = {\n",
    "            'crtfc_key': api_key,\n",
    "            'corp_code': corp_code,\n",
    "            'bsns_year': year,\n",
    "            'reprt_code': '11011'\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            total_outstanding_shares = 0\n",
    "            for entry in data.get('list', []):\n",
    "                outstanding_shares = entry.get('istc_totqy', '0').replace(',', '')\n",
    "                if outstanding_shares.isdigit():\n",
    "                    total_outstanding_shares += int(outstanding_shares)\n",
    "                    \n",
    "            results.append({\n",
    "                'company_name': corp_name,\n",
    "                'year': year,\n",
    "                'total_outstanding_shares': total_outstanding_shares\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            print(f'Error: Unable to fetch data for {corp_name} in {year}. HTTP Status code: {response.status_code}')\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df = df.pivot(index='company_name', columns='year', values='total_outstanding_shares')\n",
    "\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "outstanding_shares = pd.read_csv('outstanding_shares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_outstanding_shares = pd.melt(outstanding_shares, id_vars=[\"company_name\"], var_name=\"year\", value_name=\"outstanding_shares\")\n",
    "feature_outstanding_shares = feature_outstanding_shares.rename(columns={'company_name': 'corp'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_liabilities = bs[bs['label_en']=='total liabilities'] \n",
    "\n",
    "total_liabilities.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "find_missing_corps(bs, total_liabilities)\n",
    "\n",
    "feature_total_liabilities = process_feature(total_liabilities.copy(), 'total_liabilities') \n",
    "\n",
    "feature_total_liabilities = feature_total_liabilities.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corp</th>\n",
       "      <th>year</th>\n",
       "      <th>total_liabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>2018</td>\n",
       "      <td>2.083331e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.455914e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.300163e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>2021</td>\n",
       "      <td>9.925344e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.119560e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>흥아해운</td>\n",
       "      <td>2018</td>\n",
       "      <td>7.305503e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>흥아해운</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.000433e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>흥아해운</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.130598e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>흥아해운</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.443589e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>흥아해운</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.817552e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3265 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        corp  year  total_liabilities\n",
       "0     AJ네트웍스  2018       2.083331e+12\n",
       "1     AJ네트웍스  2019       1.455914e+12\n",
       "2     AJ네트웍스  2020       1.300163e+12\n",
       "3     AJ네트웍스  2021       9.925344e+11\n",
       "4     AJ네트웍스  2022       1.119560e+12\n",
       "...      ...   ...                ...\n",
       "3260    흥아해운  2018       7.305503e+11\n",
       "3261    흥아해운  2019       4.000433e+11\n",
       "3262    흥아해운  2020       3.130598e+11\n",
       "3263    흥아해운  2021       1.443589e+11\n",
       "3264    흥아해운  2022       1.817552e+11\n",
       "\n",
       "[3265 rows x 3 columns]"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_total_liabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_assets = bs[bs['label_en']=='total assets']  \n",
    "\n",
    "total_assets.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "find_missing_corps(bs, total_assets)\n",
    "\n",
    "feature_total_assets = process_feature(total_assets.copy(), 'total_assets')\n",
    "\n",
    "feature_total_assets = feature_total_assets.reset_index(drop=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash Flow Per Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfps_list = ['cash flows from (used in) operating activities', 'cash flows from operating activities', 'operating activity cash flow', 'net cash flows from operating activities', 'operating activities', 'i. cash flows from (used in) operating activities']\n",
    "\n",
    "cfps = cf[cf['label_en'].isin((\n",
    "    cfps_list\n",
    "))]\n",
    "\n",
    "cfps = cfps.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "find_missing_corps(cf, cfps)\n",
    "\n",
    "feature_cash_flow = process_feature(cfps.copy(), 'cash_flow')\n",
    "\n",
    "feature_cash_flow.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(feature_cash_flow, feature_outstanding_shares, on=['corp', 'year'])\n",
    "\n",
    "merged_df['cash_flow_per_share'] = merged_df['cash_flow'] / merged_df['outstanding_shares']\n",
    "\n",
    "feature_cash_flow_per_share = merged_df.drop(columns=['cash_flow', 'outstanding_shares']) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Per Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(feature_revenue, feature_outstanding_shares, on=['corp', 'year'])\n",
    "\n",
    "merged_df['sales_per_share'] = merged_df['revenue'] / merged_df['outstanding_shares']\n",
    "\n",
    "feature_sales_per_share = merged_df[['corp', 'year', 'sales_per_share']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_assets = bs[bs['label_en']=='current assets'].drop_duplicates(subset='corp', keep='first') \n",
    "\n",
    "feature_current_assets = process_feature(current_assets.copy(), 'current_assets') \n",
    "feature_current_assets = feature_current_assets.reset_index(drop=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_liabilities = bs[bs['label_en']=='current liabilities'].drop_duplicates(subset='corp', keep='first') \n",
    "\n",
    "feature_current_liabilities = process_feature(current_liabilities.copy(), 'current_liabilities') \n",
    "feature_current_liabilities = feature_current_liabilities.reset_index(drop=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories_list = ['inventories']\n",
    "\n",
    "inventories = bs[bs['label_en'].isin((\n",
    "    inventories_list\n",
    "))]\n",
    "\n",
    "inventories = inventories.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "inventories = process_feature(inventories.copy(), 'inventory')\n",
    "\n",
    "find_missing_corps(bs, inventories) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "corps = list(find_missing_corps(bs, inventories))\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "data = []\n",
    "for corp in corps:\n",
    "    for year in years:\n",
    "        data.append({'corp': corp, 'year': year, 'inventory': 0})\n",
    "\n",
    "inventory_df = pd.DataFrame(data)\n",
    "\n",
    "feature_inventory = pd.concat([inventories, inventory_df], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Working Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(feature_revenue, feature_outstanding_shares, on=['corp', 'year'])\n",
    "\n",
    "merged_df['sales_per_share'] = merged_df['revenue'] / merged_df['outstanding_shares']\n",
    "\n",
    "feature_sales_per_share = merged_df[['corp', 'year', 'sales_per_share']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(feature_current_assets, feature_current_liabilities, on=['corp', 'year'])\n",
    "\n",
    "merged_df['net_working_capital'] = merged_df['current_assets'] - merged_df['current_liabilities'] \n",
    "\n",
    "feature_net_working_capital = merged_df[['corp', 'year', 'net_working_capital']] \n",
    "\n",
    "feature_net_working_capital\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-current Assets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_current_assets_list = ['non-current assets']\n",
    "\n",
    "non_current_assets = bs[bs['label_en'].isin((\n",
    "    non_current_assets_list\n",
    "))]\n",
    "\n",
    "non_current_assets = non_current_assets.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "non_current_assets = process_feature(non_current_assets.copy(), 'non_current_assets')\n",
    "\n",
    "feature_non_current_assets = non_current_assets.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-current Liabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_current_liabilities_list = ['non-current liabilities']\n",
    "\n",
    "non_current_liabilities = bs[bs['label_en'].isin((\n",
    "    non_current_liabilities_list\n",
    "))]\n",
    "\n",
    "non_current_liabilities = non_current_liabilities.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "non_current_liabilities = process_feature(non_current_liabilities.copy(), 'non_current_liabilities')\n",
    "\n",
    "feature_non_current_liabilities = non_current_liabilities.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [feature_operating_income, feature_revenue, feature_net_income,\n",
    "                feature_outstanding_shares, feature_total_liabilities,\n",
    "                feature_total_assets, feature_cash_flow_per_share,\n",
    "                feature_sales_per_share, feature_current_assets,\n",
    "                feature_current_liabilities, feature_inventory,\n",
    "                feature_net_working_capital, feature_non_current_assets,\n",
    "                feature_non_current_liabilities] \n",
    "\n",
    "feature_combined = feature_list[0]\n",
    "\n",
    "for feature_df in feature_list[1:]:\n",
    "    feature_combined = pd.merge(feature_combined, feature_df, on=['corp', 'year'])\n",
    "    \n",
    "feature_combined.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_combined.to_csv('feature_combined.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Combined 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_operation(cis, company_name, feature_name, feat1, feat2, operation, years=['2018', '2019', '2020', '2021', '2022']):\n",
    "    \n",
    "    # Filter the rows for the given company and features\n",
    "    feature_1 = cis.loc[(cis['label_en'] == feat1) & (cis['corp'] == company_name), years]\n",
    "    feature_2 = cis.loc[(cis['label_en'] == feat2) & (cis['corp'] == company_name), years]\n",
    "    \n",
    "    # Initialize result list\n",
    "    result_list = []\n",
    "    \n",
    "    # Iterate through each year and perform the specified operation\n",
    "    for year in years:\n",
    "        values1 = feature_1[year].values\n",
    "        values2 = feature_2[year].values\n",
    "\n",
    "        # Check if values are present for both features in the given year\n",
    "        if values1.size > 0 and values2.size > 0:\n",
    "            # Perform the specified operation\n",
    "            if operation == 'divide':\n",
    "                result = values1[0] / values2[0]\n",
    "            elif operation == 'add':\n",
    "                result = values1[0] + values2[0]\n",
    "            else:\n",
    "                result = np.nan\n",
    "        else:\n",
    "            result = np.nan\n",
    "        \n",
    "        # Add the result to the list\n",
    "        result_list.append({'corp': company_name, 'year': year, feature_name: result})\n",
    "    \n",
    "    # Convert the result list to a DataFrame\n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "operating_income = cis[cis['label_en'].isin((\n",
    "    'operating income(loss)', \n",
    "    'sales account', \n",
    "    'operating loss', \n",
    "    'operating income', \n",
    "    'operating profit', \n",
    "    'operating profit (loss)',\n",
    "    'operating profit(loss)',\n",
    "    'operating profits'\n",
    "))]\n",
    "\n",
    "operating_income = operating_income.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "find_missing_corps(cis, operating_income) \n",
    "\n",
    "feature_operating_income = process_feature(operating_income.copy(), 'operating_income') \n",
    "\n",
    "feature_operating_income = feature_operating_income.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LG유플러스', 'LX홀딩스', '대웅', '아이에이치큐', '카카오', '케이티스카이라이프'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "revenue_list = ['revenue(sales)', 'revenue', 'sales(revenue)', 'sales', 'sales of goods', 'net sales', 'sales income', 'sales account']\n",
    "\n",
    "revenue = cis[cis['label_en'].isin((\n",
    "    revenue_list\n",
    "))]\n",
    "\n",
    "revenue = revenue.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "feature_revenue = process_feature(revenue.copy(), 'revenue') \n",
    "\n",
    "find_missing_corps(cis, revenue) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue1 = feature_operation(cis, 'LG유플러스', 'revenue', 'operating income', 'operating expenses', 'divide')\n",
    "revenue2 = feature_operation(cis, 'LX홀딩스', 'revenue', 'operating income', 'operating expenses', 'divide')\n",
    "revenue3 = feature_operation(cis, '대웅', 'revenue', 'duddjqtndlr', 'selling general administrative expenses', 'add')\n",
    "revenue4 = feature_operation(cis, '아이에이치큐', 'revenue', 'gross profit', 'selling general administrative expenses', 'add')\n",
    "revenue5 = feature_operation(cis, '카카오', 'revenue', 'gross profit', 'selling general administrative expenses', 'add')\n",
    "revenue6 = feature_operation(cis, '케이티스카이라이프', 'revenue', 'operating revenues', 'operating expenses', 'add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue1 = feature_operation(cis, 'LG유플러스', 'revenue', 'operating income', 'operating expenses', 'divide', years)\n",
    "revenue2 = feature_operation(cis, 'LX홀딩스', 'revenue', 'operating income', 'operating expenses', 'divide', years)\n",
    "revenue3 = feature_operation(cis, '대웅', 'revenue', 'duddjqtndlr', 'selling general administrative expenses', 'add', years)\n",
    "revenue4 = feature_operation(cis, '아이에이치큐', 'revenue', 'gross profit', 'selling general administrative expenses', 'add', years)\n",
    "revenue5 = feature_operation(cis, '카카오', 'revenue', 'gross profit', 'selling general administrative expenses', 'add', years)\n",
    "revenue6 = feature_operation(cis, '케이티스카이라이프', 'revenue', 'operating revenues', 'operating expenses', 'add', years)\n",
    "\n",
    "for revenue in [revenue1, revenue2, revenue3, revenue4, revenue5, revenue6]: \n",
    "    feature_revenue = feature_revenue.append(revenue) \n",
    "\n",
    "feature_revenue = feature_revenue.reset_index(drop=True)\n",
    "\n",
    "feature_revenue = feature_revenue.drop_duplicates(subset=['corp', 'year'], keep='first')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'남해화학', '일진전기'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_income_list = ['profit', 'profit (loss)', 'profit(loss)', 'profit (loss) for the period', 'profit(loss) for the period', 'profit (loss) for the year',\n",
    "'loss (profit)', 'net income(loss)', 'net income', 'profit for the year', 'quarterly net income, attributable to', 'semiannual net profit',\n",
    "'net profit during thr current term', 'the year net profit(loss)', 'net profit', 'ifrs_profitloss', 'quarterly net profit', '- profit (loss)']\n",
    "\n",
    "net_income = cis[cis['label_en'].isin((\n",
    "    net_income_list\n",
    "))]\n",
    "\n",
    "net_income = net_income.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "net_income = process_feature(net_income.copy(), 'net_income')\n",
    "\n",
    "find_missing_corps(cis, net_income) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (cis['corp'] == '일진전기') & (cis['label_en'] == 'profit (loss), attributable to non-controlling interests')\n",
    "cis.loc[mask, '2018'] = 0\n",
    "cis.loc[mask, '2019'] = 0\n",
    "cis.loc[mask, '2020'] = 0\n",
    "cis.loc[mask, '2021'] = 0\n",
    "cis.loc[mask, '2022'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_income_1 = feature_operation(cis, '남해화학', 'net_income', 'profit (loss), attributable to owners of parent', 'profit (loss), attributable to non-controlling interests', 'add', years)\n",
    "net_income_2 = feature_operation(cis, '일진전기', 'net_income', 'profit (loss), attributable to owners of parent', 'profit (loss), attributable to non-controlling interests', 'add', years)\n",
    "\n",
    "feature_net_income = net_income.append([net_income_1, net_income_2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Outstanding Shares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='58b7a0538b393d6c96f7f93b31101d5f407c9d1d'\n",
    "dart.set_api_key(api_key=api_key)\n",
    "\n",
    "corp_list = dart.get_corp_list()\n",
    "kospi_list = corp_list.find_by_corp_name(corp_name='', market='Y')\n",
    "\n",
    "successful_list = list(bs['corp'].unique())\n",
    "kospi_list = [comp.corp_name for comp in kospi_list]\n",
    "failed_list = [comp for comp in kospi_list if comp not in successful_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "corp_dict = {} \n",
    "\n",
    "kospi_list \n",
    "\n",
    "for comp in kospi_list: \n",
    "    corp_dict[comp.corp_name] = comp.corp_code \n",
    "\n",
    "for key in failed_list:\n",
    "    if key in corp_dict:\n",
    "        del corp_dict[key]\n",
    "\n",
    "url = 'https://opendart.fss.or.kr/api/stockTotqySttus.json'\n",
    "api_key = '58b7a0538b393d6c96f7f93b31101d5f407c9d1d'\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "results = []\n",
    "\n",
    "for corp_name, corp_code in corp_dict.items():\n",
    "    for year in years:\n",
    "        params = {\n",
    "            'crtfc_key': api_key,\n",
    "            'corp_code': corp_code,\n",
    "            'bsns_year': year,\n",
    "            'reprt_code': '11011'\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            total_outstanding_shares = 0\n",
    "            for entry in data.get('list', []):\n",
    "                outstanding_shares = entry.get('istc_totqy', '0').replace(',', '')\n",
    "                if outstanding_shares.isdigit():\n",
    "                    total_outstanding_shares += int(outstanding_shares)\n",
    "                    \n",
    "            results.append({\n",
    "                'company_name': corp_name,\n",
    "                'year': year,\n",
    "                'total_outstanding_shares': total_outstanding_shares\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            print(f'Error: Unable to fetch data for {corp_name} in {year}. HTTP Status code: {response.status_code}')\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df = df.pivot(index='company_name', columns='year', values='total_outstanding_shares')\n",
    "\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outstanding_shares = pd.read_csv('outstanding_shares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_outstanding_shares = pd.melt(outstanding_shares, id_vars=[\"company_name\"], var_name=\"year\", value_name=\"outstanding_shares\")\n",
    "feature_outstanding_shares = feature_outstanding_shares.rename(columns={'company_name': 'corp'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_liabilities = bs[bs['label_en']=='total liabilities'] \n",
    "\n",
    "total_liabilities.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "find_missing_corps(bs, total_liabilities)\n",
    "\n",
    "feature_total_liabilities = process_feature(total_liabilities.copy(), 'total_liabilities') \n",
    "\n",
    "feature_total_liabilities = feature_total_liabilities.reset_index(drop=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_assets = bs[bs['label_en']=='total assets']  \n",
    "\n",
    "total_assets.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "find_missing_corps(bs, total_assets)\n",
    "\n",
    "feature_total_assets = process_feature(total_assets.copy(), 'total_assets')\n",
    "\n",
    "feature_total_assets = feature_total_assets.reset_index(drop=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash Flow Per Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfps_list = ['cash flows from (used in) operating activities', 'cash flows from operating activities', 'operating activity cash flow', 'net cash flows from operating activities', 'operating activities', 'i. cash flows from (used in) operating activities', 'cash flows from (used in) operating activities.', 'net cash flow from operating activities', 'cash flows provided by operating activities', 'cash flows from operating activities', 'net cash flows from used in operations']\n",
    "\n",
    "cfps = cf[cf['label_en'].isin(cfps_list)]\n",
    "\n",
    "cfps['nonnull_count'] = cfps[['2018', '2019', '2020', '2021', '2022']].count(axis=1)\n",
    "\n",
    "cfps.sort_values('nonnull_count', ascending=False, inplace=True)\n",
    "\n",
    "cfps.drop_duplicates(subset='corp', keep='first', inplace=True)\n",
    "\n",
    "find_missing_corps(cf, cfps)\n",
    "\n",
    "feature_cash_flow = process_feature(cfps.copy(), 'cash_flow')\n",
    "\n",
    "feature_cash_flow.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(feature_cash_flow, feature_outstanding_shares, on=['corp', 'year'])\n",
    "\n",
    "merged_df['cash_flow_per_share'] = merged_df['cash_flow'] / merged_df['outstanding_shares']\n",
    "\n",
    "feature_cash_flow_per_share = merged_df.drop(columns=['cash_flow', 'outstanding_shares']) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Per Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(feature_revenue, feature_outstanding_shares, on=['corp', 'year'])\n",
    "\n",
    "merged_df['sales_per_share'] = merged_df['revenue'] / merged_df['outstanding_shares']\n",
    "\n",
    "feature_sales_per_share = merged_df[['corp', 'year', 'sales_per_share']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_assets = bs[bs['label_en']=='current assets'].drop_duplicates(subset='corp', keep='first') \n",
    "\n",
    "feature_current_assets = process_feature(current_assets.copy(), 'current_assets') \n",
    "feature_current_assets = feature_current_assets.reset_index(drop=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_liabilities = bs[bs['label_en']=='current liabilities'].drop_duplicates(subset='corp', keep='first') \n",
    "\n",
    "feature_current_liabilities = process_feature(current_liabilities.copy(), 'current_liabilities') \n",
    "feature_current_liabilities = feature_current_liabilities.reset_index(drop=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories_list = ['inventories']\n",
    "\n",
    "inventories = bs[bs['label_en'].isin((\n",
    "    inventories_list\n",
    "))]\n",
    "\n",
    "inventories = inventories.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "inventories = process_feature(inventories.copy(), 'inventory')\n",
    "\n",
    "find_missing_corps(bs, inventories) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corps = list(find_missing_corps(bs, inventories))\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "data = []\n",
    "for corp in corps:\n",
    "    for year in years:\n",
    "        data.append({'corp': corp, 'year': year, 'inventory': 0})\n",
    "\n",
    "inventory_df = pd.DataFrame(data)\n",
    "\n",
    "feature_inventory = pd.concat([inventories, inventory_df], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Working Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(feature_current_assets, feature_current_liabilities, on=['corp', 'year'])\n",
    "\n",
    "merged_df['net_working_capital'] = merged_df['current_assets'] - merged_df['current_liabilities'] \n",
    "\n",
    "feature_net_working_capital = merged_df[['corp', 'year', 'net_working_capital']] \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-current Assets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_current_assets_list = ['non-current assets']\n",
    "\n",
    "non_current_assets = bs[bs['label_en'].isin((\n",
    "    non_current_assets_list\n",
    "))]\n",
    "\n",
    "non_current_assets = non_current_assets.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "non_current_assets = process_feature(non_current_assets.copy(), 'non_current_assets')\n",
    "\n",
    "feature_non_current_assets = non_current_assets.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-current Liabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_current_liabilities_list = ['non-current liabilities']\n",
    "\n",
    "non_current_liabilities = bs[bs['label_en'].isin((\n",
    "    non_current_liabilities_list\n",
    "))]\n",
    "\n",
    "non_current_liabilities = non_current_liabilities.drop_duplicates(subset='corp', keep='first')\n",
    "\n",
    "non_current_liabilities = process_feature(non_current_liabilities.copy(), 'non_current_liabilities')\n",
    "\n",
    "feature_non_current_liabilities = non_current_liabilities.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [feature_operating_income, feature_revenue, feature_net_income,\n",
    "                feature_outstanding_shares, feature_total_liabilities,\n",
    "                feature_total_assets, feature_cash_flow_per_share,\n",
    "                feature_sales_per_share, feature_current_assets,\n",
    "                feature_current_liabilities, feature_inventory,\n",
    "                feature_net_working_capital, feature_non_current_assets,\n",
    "                feature_non_current_liabilities] \n",
    "\n",
    "feature_combined = feature_list[0]\n",
    "\n",
    "for feature_df in feature_list[1:]:\n",
    "    feature_combined = pd.merge(feature_combined, feature_df, on=['corp', 'year'])\n",
    "    \n",
    "feature_combined.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3265, 16)"
      ]
     },
     "execution_count": 1330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_combined.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 how? \n",
    "\n",
    "1. 2022 없으면 그 corp다 삭제 \n",
    "\n",
    "2. 2021 & 2022는 있는데 2018, 2019, 2020 없음 -> 그냥 2018 2019 2020 row 제거 \n",
    "\n",
    "3. 이렇게 하고 나면 30 Rows 남는데 대부분이 발행주식수(outstanding_shares) 데이터가 없어서 cash_flow_per_share & sales_per_share 값이 null값임 -> 제거 \n",
    "\n",
    "4. 나머지 8 Rows는 operating income, revenue, net income, inventory, assets 이런 데이터가 없음. 3000+ rows중에 8개라서 그냥 없어도 분석에는 지장이 없음 -> 제거 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 corps have been removed since there's no relevant data for 2022\n"
     ]
    }
   ],
   "source": [
    "mask = (feature_combined['year'] == '2022') & (feature_combined.isnull().any(axis=1))\n",
    "\n",
    "null_2022 = feature_combined.loc[mask]\n",
    "\n",
    "corps_to_remove = null_2022['corp'].tolist()\n",
    "\n",
    "print(f\"{len(corps_to_remove)} corps have been removed since there's no relevant data for 2022\")\n",
    "\n",
    "feature_combined = feature_combined[~feature_combined['corp'].isin(corps_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3160, 16)"
      ]
     },
     "execution_count": 1332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632"
      ]
     },
     "execution_count": 1333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_combined['corp'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = feature_combined[feature_combined.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = null_rows.isnull().sum(axis=1) >= 5\n",
    "\n",
    "corps_and_years_to_remove = null_rows.loc[mask, ['corp', 'year']].values.tolist()\n",
    "\n",
    "original_corp_len = len(feature_combined['corp'].unique()) \n",
    "\n",
    "for corp, year in corps_and_years_to_remove:\n",
    "    mask = (feature_combined['corp'] == corp) & (feature_combined['year'] == year)\n",
    "    feature_combined = feature_combined[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3087, 16)"
      ]
     },
     "execution_count": 1336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_combined.to_csv('feature_combined.csv', encoding='utf-8-sig', index=False)\n",
    "null_rows = feature_combined[feature_combined.isnull().any(axis=1)]\n",
    "null_rows.to_csv('null_rows.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = feature_combined[feature_combined.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [],
   "source": [
    "corps_and_years_to_remove = null_rows[['corp', 'year']].values.tolist()\n",
    "\n",
    "for corp, year in corps_and_years_to_remove:\n",
    "    mask = (feature_combined['corp'] == corp) & (feature_combined['year'] == year)\n",
    "    feature_preprocessed = feature_combined[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3057, 16)"
      ]
     },
     "execution_count": 1347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_preprocessed.to_csv('feature_preprocessed.csv', encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
