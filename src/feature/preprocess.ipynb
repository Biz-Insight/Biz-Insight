{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes from Original DART API CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/qrlg6jnd1l5b_xdkq486q0zr0000gn/T/ipykernel_11908/286015425.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  bs = pd.read_sql(query, cnx)  # bs = pd.read_csv('bs.csv')\n",
      "/var/folders/_r/qrlg6jnd1l5b_xdkq486q0zr0000gn/T/ipykernel_11908/286015425.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  incs = pd.read_sql(query, cnx)  # incs = pd.read_csv('incs.csv')\n",
      "/var/folders/_r/qrlg6jnd1l5b_xdkq486q0zr0000gn/T/ipykernel_11908/286015425.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  cf = pd.read_sql(query, cnx)  # cf = pd.read_csv('cf.csv')\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "cnx = pymysql.connect(\n",
    "    user=\"*****\",\n",
    "    password=\"*****!\",\n",
    "    host=\"ec2-15-152-211-160.ap-northeast-3.compute.amazonaws.com\",\n",
    "    database=\"Data_Lake\",\n",
    ")\n",
    "\n",
    "query = \"SELECT * FROM bs;\"\n",
    "bs = pd.read_sql(query, cnx)  # bs = pd.read_csv('bs.csv')\n",
    "\n",
    "query = \"SELECT * FROM incs;\"\n",
    "incs = pd.read_sql(query, cnx)  # incs = pd.read_csv('incs.csv')\n",
    "\n",
    "query = \"SELECT * FROM cf;\"\n",
    "cf = pd.read_sql(query, cnx)  # cf = pd.read_csv('cf.csv')\n",
    "\n",
    "cnx.close()\n",
    "\n",
    "bs[\"label_en\"] = bs[\"label_en\"].str.lower()\n",
    "incs[\"label_en\"] = incs[\"label_en\"].str.lower()\n",
    "cf[\"label_en\"] = cf[\"label_en\"].str.lower()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USEFUL FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feature(df, prefix):\n",
    "\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "\n",
    "    for year in years:\n",
    "        original_column = f\"{prefix}_{year}\"\n",
    "        new_column = year\n",
    "        df.rename(columns={original_column: new_column}, inplace=True)\n",
    "\n",
    "    final_df = pd.melt(\n",
    "        df, id_vars=[\"corp\"], value_vars=years, var_name=\"year\", value_name=prefix\n",
    "    )\n",
    "\n",
    "    final_df = final_df.sort_values(by=[\"corp\", \"year\"]).reset_index(drop=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def find_missing_corps(main_df, subset_df):\n",
    "    main_corp_unique = set(main_df[\"corp\"].unique())\n",
    "    subset_corp_unique = set(subset_df[\"corp\"].unique())\n",
    "\n",
    "    missing_corps = main_corp_unique - subset_corp_unique\n",
    "\n",
    "    return missing_corps\n",
    "\n",
    "\n",
    "def custom_drop_logic(group):\n",
    "    null_counts = group.isnull().sum(axis=1)\n",
    "    return group.loc[null_counts.idxmin()]\n",
    "\n",
    "\n",
    "def feature_operation(\n",
    "    incs,\n",
    "    company_name,\n",
    "    feature_name,\n",
    "    feat1,\n",
    "    feat2,\n",
    "    years=[\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"],\n",
    "):\n",
    "\n",
    "    feature_1 = incs.loc[\n",
    "        (incs[\"label_en\"] == feat1) & (incs[\"corp\"] == company_name), years\n",
    "    ]\n",
    "    feature_2 = incs.loc[\n",
    "        (incs[\"label_en\"] == feat2) & (incs[\"corp\"] == company_name), years\n",
    "    ]\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for year in years:\n",
    "        values1 = feature_1[year].values\n",
    "        values2 = feature_2[year].values\n",
    "\n",
    "        if values1.size > 0 and values2.size > 0:\n",
    "            result = values1[0] + values2[0]\n",
    "        else:\n",
    "            result = np.nan\n",
    "\n",
    "        result_list.append({\"corp\": company_name, \"year\": year, feature_name: result})\n",
    "\n",
    "    result_df = pd.DataFrame(result_list)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales (Revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"LG유플러스\") & (incs[\"label_en\"] == \"operating income\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"LX홀딩스\") & (incs[\"label_en\"] == \"operating income\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"대웅\") & (incs[\"label_en\"] == \"duddjqtndlr\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"아이에이치큐\") & (incs[\"label_en\"] == \"gross profit\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"카카오\") & (incs[\"label_en\"] == \"gross profit\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"케이티스카이라이프\") & (incs[\"label_en\"] == \"operating revenues\"),\n",
    "    \"label_en\",\n",
    "] = \"revenue\"\n",
    "\n",
    "revenue_list = [\n",
    "    \"revenue(sales)\",\n",
    "    \"revenue\",\n",
    "    \"sales(revenue)\",\n",
    "    \"sales\",\n",
    "    \"sales of goods\",\n",
    "    \"net sales\",\n",
    "    \"sales income\",\n",
    "    \"sales account\",\n",
    "]\n",
    "\n",
    "revenue = incs[incs[\"label_en\"].isin((revenue_list))]\n",
    "\n",
    "revenue = revenue.drop_duplicates(subset=\"corp\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"LG유플러스\") & (incs[\"label_en\"] == \"operating income\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"LX홀딩스\") & (incs[\"label_en\"] == \"operating income\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"대웅\") & (incs[\"label_en\"] == \"duddjqtndlr\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"아이에이치큐\") & (incs[\"label_en\"] == \"gross profit\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"카카오\") & (incs[\"label_en\"] == \"gross profit\"), \"label_en\"\n",
    "] = \"revenue\"\n",
    "incs.loc[\n",
    "    (incs[\"corp\"] == \"케이티스카이라이프\") & (incs[\"label_en\"] == \"operating revenues\"),\n",
    "    \"label_en\",\n",
    "] = \"revenue\"\n",
    "\n",
    "revenue_list = [\n",
    "    \"revenue(sales)\",\n",
    "    \"revenue\",\n",
    "    \"sales(revenue)\",\n",
    "    \"sales\",\n",
    "    \"sales of goods\",\n",
    "    \"net sales\",\n",
    "    \"sales income\",\n",
    "    \"sales account\",\n",
    "]\n",
    "\n",
    "revenue = incs[incs[\"label_en\"].isin((revenue_list))]\n",
    "\n",
    "revenue = revenue.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_revenue = process_feature(revenue.copy(), \"revenue\")\n",
    "\n",
    "find_missing_corps(incs, revenue)\n",
    "\n",
    "mask = (feature_revenue[\"corp\"] == \"신성이엔지\") & (feature_revenue[\"year\"] == \"2018\")\n",
    "feature_revenue.loc[mask] = feature_revenue.loc[mask].fillna(425000000000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost of Goods sold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_of_sales_list = [\"cost of sales\"]\n",
    "\n",
    "cost_of_sales = incs[incs[\"label_en\"].isin((cost_of_sales_list))]\n",
    "\n",
    "cost_of_sales = cost_of_sales.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_cost_of_sales = process_feature(cost_of_sales.copy(), \"cost_of_sales\")\n",
    "\n",
    "find_missing_corps(incs, cost_of_sales)\n",
    "\n",
    "for corp in find_missing_corps(incs, cost_of_sales):\n",
    "    for year in [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]:\n",
    "        missing_corp_data = {\"corp\": corp, \"year\": year, \"cost_of_sales\": 0}\n",
    "        feature_cost_of_sales = feature_cost_of_sales.append(\n",
    "            missing_corp_data, ignore_index=True\n",
    "        )\n",
    "\n",
    "mask = (feature_cost_of_sales[\"corp\"] == \"에스케이바이오팜\") & (\n",
    "    feature_cost_of_sales[\"year\"] == \"2018\"\n",
    ")\n",
    "feature_cost_of_sales.loc[mask] = feature_cost_of_sales.loc[mask].fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/qrlg6jnd1l5b_xdkq486q0zr0000gn/T/ipykernel_11908/993110306.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"gross_profit\"] = filtered_df[\"revenue\"] - filtered_df[\"cost_of_sales\"]\n"
     ]
    }
   ],
   "source": [
    "gross_profit_list = [\"gross profit\"]\n",
    "\n",
    "gross_profit = incs[incs[\"label_en\"].isin((gross_profit_list))]\n",
    "\n",
    "gross_profit = gross_profit.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_gross_profit = process_feature(gross_profit.copy(), \"gross_profit\")\n",
    "\n",
    "merged_df = pd.merge(feature_revenue, feature_cost_of_sales, on=[\"corp\", \"year\"])\n",
    "\n",
    "companies = find_missing_corps(incs, gross_profit)\n",
    "filtered_df = merged_df[merged_df[\"corp\"].isin(companies)]\n",
    "\n",
    "filtered_df[\"gross_profit\"] = filtered_df[\"revenue\"] - filtered_df[\"cost_of_sales\"]\n",
    "\n",
    "gross_profit_to_append = filtered_df[[\"corp\", \"year\", \"gross_profit\"]]\n",
    "\n",
    "feature_gross_profit = feature_gross_profit.append(gross_profit_to_append)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "operating_income_ko_list = [\"영업수익\"]\n",
    "operating_income_list = [\n",
    "    \"operating income(loss)\",\n",
    "    \"sales account\",\n",
    "    \"operating loss\",\n",
    "    \"operating income\",\n",
    "    \"operating profit\",\n",
    "    \"operating profit (loss)\",\n",
    "    \"operating profit(loss)\",\n",
    "    \"operating profits\",\n",
    "]\n",
    "\n",
    "operating_income = incs[\n",
    "    (incs[\"label_en\"].isin(operating_income_list))\n",
    "    | (incs[\"label_ko\"].isin(operating_income_ko_list))\n",
    "]\n",
    "\n",
    "filtered_operating_income = operating_income.groupby(\"corp\", group_keys=False).apply(\n",
    "    custom_drop_logic\n",
    ")\n",
    "\n",
    "feature_operating_income = process_feature(\n",
    "    filtered_operating_income.copy(), \"operating_income\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_income_list = [\n",
    "    \"profit\",\n",
    "    \"profit (loss)\",\n",
    "    \"profit(loss)\",\n",
    "    \"profit (loss) for the period\",\n",
    "    \"profit(loss) for the period\",\n",
    "    \"profit (loss) for the year\",\n",
    "    \"loss (profit)\",\n",
    "    \"net income(loss)\",\n",
    "    \"net income\",\n",
    "    \"profit for the year\",\n",
    "    \"quarterly net income, attributable to\",\n",
    "    \"semiannual net profit\",\n",
    "    \"net profit during thr current term\",\n",
    "    \"the year net profit(loss)\",\n",
    "    \"net profit\",\n",
    "    \"ifrs_profitloss\",\n",
    "    \"quarterly net profit\",\n",
    "    \"- profit (loss)\",\n",
    "]\n",
    "\n",
    "net_income = incs[incs[\"label_en\"].isin((net_income_list))]\n",
    "\n",
    "net_income = net_income.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_net_income = process_feature(net_income.copy(), \"net_income\")\n",
    "\n",
    "mask = (incs[\"corp\"] == \"일진전기\") & (\n",
    "    incs[\"label_en\"] == \"profit (loss), attributable to non-controlling interests\"\n",
    ")\n",
    "incs.loc[mask, \"2018\"] = 0\n",
    "incs.loc[mask, \"2019\"] = 0\n",
    "incs.loc[mask, \"2020\"] = 0\n",
    "incs.loc[mask, \"2021\"] = 0\n",
    "incs.loc[mask, \"2022\"] = 0\n",
    "\n",
    "net_income_1 = feature_operation(\n",
    "    incs,\n",
    "    \"남해화학\",\n",
    "    \"net_income\",\n",
    "    \"profit (loss), attributable to owners of parent\",\n",
    "    \"profit (loss), attributable to non-controlling interests\",\n",
    ")\n",
    "net_income_2 = feature_operation(\n",
    "    incs,\n",
    "    \"일진전기\",\n",
    "    \"net_income\",\n",
    "    \"profit (loss), attributable to owners of parent\",\n",
    "    \"profit (loss), attributable to non-controlling interests\",\n",
    ")\n",
    "\n",
    "feature_net_income = feature_net_income.append(\n",
    "    [net_income_1, net_income_2]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "mask = (feature_net_income[\"corp\"] == \"미원홀딩스\") & (feature_net_income[\"year\"] == \"2018\")\n",
    "feature_net_income.loc[mask] = feature_net_income.loc[mask].fillna(9740481883)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBITDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EBIT\n",
    "ebit_list = [\n",
    "    \"profit (loss) before income tax expense\",\n",
    "    \"net profit before income tax\",\n",
    "    \"profit (loss) before tax\",\n",
    "    \"profit before tax(loss)\",\n",
    "    \"profit (loss) before income tax\",\n",
    "    \"income before income tax expenses\",\n",
    "    \"profit  before tax\",\n",
    "    \"profit before income tax\",\n",
    "    \"profit (loss) from continuing operations before tax\",\n",
    "    \"income before income tax\",\n",
    "    \"profit before tax\",\n",
    "    \"profit (loss) before tax from continuing operations\",\n",
    "    \"profit(loss) before tax\",\n",
    "    \"net loss before income tax expense deduction\",\n",
    "    \"loss (profit) before tax\",\n",
    "    \"net income before income tax expense\",\n",
    "    \"net income before income tax expense (net loss)\",\n",
    "]\n",
    "\n",
    "ebit = incs[incs[\"label_en\"].isin((ebit_list))]\n",
    "\n",
    "ebit = ebit.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_ebit = process_feature(ebit.copy(), \"ebit\")\n",
    "\n",
    "find_missing_corps(incs, ebit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "depreciation_list = [\"depreciation expense\"]\n",
    "\n",
    "depreciation = incs[incs[\"label_en\"].isin((depreciation_list))]\n",
    "\n",
    "depreciation = depreciation.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_depreciation = process_feature(depreciation.copy(), \"depreciation\")\n",
    "\n",
    "find_missing_corps(incs, depreciation)\n",
    "\n",
    "feature_depreciation[\"depreciation\"].fillna(0, inplace=True)\n",
    "\n",
    "for corp in find_missing_corps(incs, depreciation):\n",
    "    for year in [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]:\n",
    "        missing_corp_data = {\"corp\": corp, \"year\": year, \"depreciation\": 0}\n",
    "        feature_depreciation = feature_depreciation.append(\n",
    "            missing_corp_data, ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "amortization_list = [\"amortization expense\", \"amortisation expense\"]\n",
    "\n",
    "amortization = incs[incs[\"label_en\"].isin((amortization_list))]\n",
    "\n",
    "amortization = amortization.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_amortization = process_feature(amortization.copy(), \"amortization\")\n",
    "\n",
    "find_missing_corps(incs, amortization)\n",
    "\n",
    "feature_amortization[\"amortization\"].fillna(0, inplace=True)\n",
    "\n",
    "for corp in find_missing_corps(incs, amortization):\n",
    "    for year in [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]:\n",
    "        missing_corp_data = {\"corp\": corp, \"year\": year, \"amortization\": 0}\n",
    "        feature_amortization = feature_amortization.append(\n",
    "            missing_corp_data, ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(feature_ebit, feature_depreciation, on=[\"corp\", \"year\"])\n",
    "merged_df = pd.merge(merged_df, feature_amortization, on=[\"corp\", \"year\"])\n",
    "\n",
    "merged_df[\"ebitda\"] = (\n",
    "    merged_df[\"ebit\"] + merged_df[\"depreciation\"] + merged_df[\"amortization\"]\n",
    ")\n",
    "\n",
    "feature_ebitda = merged_df[[\"corp\", \"year\", \"ebitda\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_equity_list = [\"total equity\", \"qq\", \"total amount of capital\", \"total equtiy\"]\n",
    "\n",
    "total_equity = bs[bs[\"label_en\"].isin((total_equity_list))]\n",
    "\n",
    "total_equity = total_equity.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_total_equity = process_feature(total_equity.copy(), \"total_equity\")\n",
    "\n",
    "find_missing_corps(bs, total_equity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_assets = bs[bs[\"label_en\"] == \"total assets\"]\n",
    "\n",
    "total_assets.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "find_missing_corps(bs, total_assets)\n",
    "\n",
    "feature_total_assets = process_feature(total_assets.copy(), \"total_assets\")\n",
    "\n",
    "feature_total_assets = feature_total_assets.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_liabilities = bs[bs[\"label_en\"] == \"total liabilities\"]\n",
    "\n",
    "total_liabilities.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "find_missing_corps(bs, total_liabilities)\n",
    "\n",
    "feature_total_liabilities = process_feature(\n",
    "    total_liabilities.copy(), \"total_liabilities\"\n",
    ")\n",
    "\n",
    "feature_total_liabilities = feature_total_liabilities.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_assets = bs[bs[\"label_en\"] == \"current assets\"].drop_duplicates(\n",
    "    subset=\"corp\", keep=\"first\"\n",
    ")\n",
    "\n",
    "feature_current_assets = process_feature(current_assets.copy(), \"current_assets\")\n",
    "feature_current_assets = feature_current_assets.reset_index(drop=True)\n",
    "\n",
    "feature_current_assets[feature_current_assets[\"corp\"] == \"아남전자\"]\n",
    "\n",
    "values_to_set = {\n",
    "    2018: 61980000000,\n",
    "    2019: 66190000000,\n",
    "    2020: 86620000000,\n",
    "    2021: 121540000000,\n",
    "    2022: 107050000000,\n",
    "}\n",
    "\n",
    "for year, value in values_to_set.items():\n",
    "    mask = (feature_current_assets[\"corp\"] == \"아남전자\") & (\n",
    "        feature_current_assets[\"year\"] == str(year)\n",
    "    )\n",
    "    feature_current_assets.loc[mask, \"current_assets\"] = value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_liabilities = bs[bs[\"label_en\"] == \"current liabilities\"].drop_duplicates(\n",
    "    subset=\"corp\", keep=\"first\"\n",
    ")\n",
    "\n",
    "feature_current_liabilities = process_feature(\n",
    "    current_liabilities.copy(), \"current_liabilities\"\n",
    ")\n",
    "feature_current_liabilities = feature_current_liabilities.reset_index(drop=True)\n",
    "\n",
    "values_to_set = {\n",
    "    2018: 26100000000,\n",
    "    2019: 30070000000,\n",
    "    2020: 50710000000,\n",
    "    2021: 74444000000,\n",
    "    2022: 48040000000,\n",
    "}\n",
    "\n",
    "for year, value in values_to_set.items():\n",
    "    mask = (feature_current_liabilities[\"corp\"] == \"아남전자\") & (\n",
    "        feature_current_liabilities[\"year\"] == str(year)\n",
    "    )\n",
    "    feature_current_liabilities.loc[mask, \"current_liabilities\"] = value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-current Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_current_liabilities_list = [\"non-current liabilities\"]\n",
    "\n",
    "non_current_liabilities = bs[bs[\"label_en\"].isin((non_current_liabilities_list))]\n",
    "\n",
    "non_current_liabilities = non_current_liabilities.drop_duplicates(\n",
    "    subset=\"corp\", keep=\"first\"\n",
    ")\n",
    "\n",
    "non_current_liabilities = process_feature(\n",
    "    non_current_liabilities.copy(), \"non_current_liabilities\"\n",
    ")\n",
    "\n",
    "feature_non_current_liabilities = non_current_liabilities.reset_index(drop=True)\n",
    "\n",
    "values_to_set = {\n",
    "    2018: 4490000000,\n",
    "    2019: 1540000000,\n",
    "    2020: 730000000,\n",
    "    2021: 6580000000,\n",
    "    2022: 4940000000,\n",
    "}\n",
    "\n",
    "for year, value in values_to_set.items():\n",
    "    mask = (feature_non_current_liabilities[\"corp\"] == \"아남전자\") & (\n",
    "        feature_non_current_liabilities[\"year\"] == str(year)\n",
    "    )\n",
    "    feature_non_current_liabilities.loc[mask, \"non_current_liabilities\"] = value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borrowings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_borrowing_list = [\n",
    "    \"short-term borrowings\",\n",
    "    \"current portion of long-term borrowings\",\n",
    "    \"current portion at llong-term borrowings\",\n",
    "    \"short-term borrowings(cash)\",\n",
    "    \"current maturities of long-term debt\",\n",
    "    \"floating debt\",\n",
    "    \"liquidity borrowings\",\n",
    "    \"short-term borrowings and current portion of long-term borrowings\",\n",
    "    \"short-term borrowings and bonds\",\n",
    "    \"current borrowings\",\n",
    "    \"a short-term loan payable\",\n",
    "    \"current payables and borrowings\",\n",
    "    \"currentliabilitiess\",\n",
    "    \"current installments of long-term debt, net\",\n",
    "    \"current financial liabilities\",\n",
    "    \"short-term borrowings and current portion of long term borrowings\",\n",
    "    \"short-term liabilities\",\n",
    "    \"loans and borrowings (currnet)\",\n",
    "    \"current portion of long-term liabilities\",\n",
    "    \"short-term borrowings and corporate bond\",\n",
    "    \"short term borrowings\",\n",
    "    \"current long-term borrowings\",\n",
    "    \"current borrowings(short-term borrowings)\",\n",
    "    \"short-term loans\",\n",
    "    \"short-term borrowings from shareholders' executives and employees\",\n",
    "    \"current portion of long-term borrowings and bonds\",\n",
    "    \"a short-term debt\",\n",
    "    \"current borrowings and bonds issued\",\n",
    "    \"short-term borrowings and current growth-term liabilities\",\n",
    "    \"short-term borrowings & current portion of bonds\",\n",
    "    \"other current financial liabilities\",\n",
    "    \"loan payable\",\n",
    "    \"current bond and longterm loan\",\n",
    "    \"current portion of liquidity long-term borrowings\",\n",
    "    \"short-term borrowings and current portion of long-term liabilities\",\n",
    "    \"short-term borrowing liability\",\n",
    "]\n",
    "short_borrowing = bs[bs[\"label_en\"].isin((short_borrowing_list))]\n",
    "\n",
    "short_borrowing = short_borrowing.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_short_borrowing = process_feature(short_borrowing.copy(), \"short_borrowing\")\n",
    "\n",
    "feature_short_borrowing = feature_short_borrowing.fillna(0)\n",
    "\n",
    "for corp in find_missing_corps(incs, short_borrowing):\n",
    "    for year in [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]:\n",
    "        missing_corp_data = {\"corp\": corp, \"year\": year, \"short_borrowing\": 0}\n",
    "        feature_short_borrowing = feature_short_borrowing.append(\n",
    "            missing_corp_data, ignore_index=True\n",
    "        )\n",
    "\n",
    "\n",
    "long_borrowing_list = [\n",
    "    \"long-term borrowings, gross and bonds issued\",\n",
    "    \"long-term borrowings, gross\",\n",
    "    \"long-term borrowings\",\n",
    "    \"long-term trade and other non-current payables\",\n",
    "    \"long-term borrowings, excluding \\ncurrent installments, net\",\n",
    "    \"borrowings and debentures\",\n",
    "    \"non-current borrowings and bonds.\",\n",
    "    \"long-term financial liabilities\",\n",
    "    \"interest-bearing loans and borrowings\",\n",
    "    \"long-term borrowings and debentures\",\n",
    "    \"bonds issued and long-term borrowings\",\n",
    "    \"long-term liabilities\",\n",
    "    \"loans and borrowings (non-current)\",\n",
    "    \"a long-term interest-bearing loan\",\n",
    "    \"bonds issued\",\n",
    "    \"non-current borrowings\",\n",
    "    \"long-term debt\",\n",
    "    \"long-term borrowings, gross and corporate bond\",\n",
    "    \"long-term borrowings, gross and etc\",\n",
    "    \"non-current borrowings(long-term borrowings, gross)\",\n",
    "    \"long-term borrowings, gross and bonds\",\n",
    "    \"long-term borrowings and bonds issued\",\n",
    "    \"non-current liabilities of borrowings\",\n",
    "    \"long term borrowings for asset securitization\",\n",
    "    \"bonds and borrowings\",\n",
    "    \"borrowings and bonds\",\n",
    "    \"long-term borrowing and bonds payable\",\n",
    "    \"non-current borrowings and bonds issued\",\n",
    "    \"long-term borrowings & bonds\",\n",
    "    \"long-term borrowing\",\n",
    "    \"liquid longterm debt\",\n",
    "    \"liquid long-term borrowings\",\n",
    "    \"long borrowings\",\n",
    "    \"other non-current financial liabilities\",\n",
    "    \"debentures and long-term borrowings\",\n",
    "    \"interest-bearing debt\",\n",
    "    \"long-term borrowing liability\",\n",
    "]\n",
    "\n",
    "long_borrowing = bs[bs[\"label_en\"].isin((long_borrowing_list))]\n",
    "\n",
    "long_borrowing = long_borrowing.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_long_borrowing = process_feature(long_borrowing.copy(), \"long_borrowing\")\n",
    "\n",
    "feature_long_borrowing = feature_long_borrowing.fillna(0)\n",
    "\n",
    "for corp in find_missing_corps(incs, long_borrowing):\n",
    "    for year in [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]:\n",
    "        missing_corp_data = {\"corp\": corp, \"year\": year, \"long_borrowing\": 0}\n",
    "        feature_long_borrowing = feature_long_borrowing.append(\n",
    "            missing_corp_data, ignore_index=True\n",
    "        )\n",
    "\n",
    "merged_borrowing = feature_short_borrowing.merge(\n",
    "    feature_long_borrowing, on=[\"corp\", \"year\"]\n",
    ")\n",
    "\n",
    "merged_borrowing[\"borrowing\"] = (\n",
    "    merged_borrowing[\"short_borrowing\"] + merged_borrowing[\"long_borrowing\"]\n",
    ")\n",
    "\n",
    "feature_borrowing = merged_borrowing[[\"corp\", \"year\", \"borrowing\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net Liabilities = Total Liabilities - Cash and Cash Equivalents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_and_equivalents_list = [\"cash and cash equivalents\"]\n",
    "\n",
    "cash_and_equivalents = bs[bs[\"label_en\"].isin((cash_and_equivalents_list))]\n",
    "\n",
    "cash_and_equivalents = cash_and_equivalents.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_cash_and_equivalents = process_feature(\n",
    "    cash_and_equivalents.copy(), \"cash_and_equivalents\"\n",
    ")\n",
    "\n",
    "find_missing_corps(bs, cash_and_equivalents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retained Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retained_earnings_list = [\n",
    "    \"retained earnings\",\n",
    "    \"retained earning\",\n",
    "    \"retainedearnings\" \"retained earnings(accumulated deficits)\",\n",
    "    \"entity00146542_udf_bs_20183261650528_equityabstract\",\n",
    "    \"accumulated deficit\",\n",
    "    \"retainedearnings\",\n",
    "    \"retained earnings(accumulated deficits)\",\n",
    "    \"retained earnings(accumulated deficit)\",\n",
    "    \"a\",\n",
    "    \"retained earnings (deficit)\",\n",
    "    \"na24\",\n",
    "]\n",
    "\n",
    "retained_earnings = bs[bs[\"label_en\"].isin((retained_earnings_list))]\n",
    "\n",
    "retained_earnings = retained_earnings.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_retained_earnings = process_feature(\n",
    "    retained_earnings.copy(), \"retained_earnings\"\n",
    ")\n",
    "\n",
    "find_missing_corps(bs, retained_earnings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Assets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed Assets = tangible assets + intangible assets\n",
    "\n",
    "# Tangible Assets\n",
    "tangible_assets_ko_list = [\"유형자산\", \"유형자산 및 사용권자산\", \"4.유형자산\"]\n",
    "tangible_assets_list = [\"tangible assets\"]\n",
    "\n",
    "tangible_assets = bs[\n",
    "    (bs[\"label_en\"].isin(tangible_assets_list))\n",
    "    | (bs[\"label_ko\"].isin(tangible_assets_ko_list))\n",
    "]\n",
    "\n",
    "filtered_tangible_assets = tangible_assets.groupby(\"corp\", group_keys=False).apply(\n",
    "    custom_drop_logic\n",
    ")\n",
    "\n",
    "feature_tangible_assets = process_feature(\n",
    "    filtered_tangible_assets.copy(), \"tangible_assets\"\n",
    ")\n",
    "\n",
    "find_missing_corps(bs, tangible_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intangible Assets\n",
    "intangible_assets_ko_list = [\"무형자산\", \"영업권및무형자산\", \"영업권 및 무형자산\", \"영업권 및 기타무형자산\"]\n",
    "\n",
    "intangible_assets_list = [\n",
    "    \"intangible assets\",\n",
    "    \"intangible assets other than goodwill\",\n",
    "    \"other intangible assets, gross\",\n",
    "    \"iintangible assets\",\n",
    "    \"goodwill&other intangible assets, gross\",\n",
    "    \"intangible assets, gross\",\n",
    "    \"goodwill, gross\",\n",
    "]\n",
    "\n",
    "intangible_assets = bs[\n",
    "    (bs[\"label_en\"].isin(intangible_assets_list))\n",
    "    | (bs[\"label_ko\"].isin(intangible_assets_ko_list))\n",
    "]\n",
    "\n",
    "intangible_assets = intangible_assets.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "feature_intangible_assets = process_feature(\n",
    "    intangible_assets.copy(), \"intangible_assets\"\n",
    ")\n",
    "\n",
    "find_missing_corps(bs, intangible_assets)\n",
    "\n",
    "feature_intangible_assets[\"intangible_assets\"].fillna(0, inplace=True)\n",
    "\n",
    "for corp in find_missing_corps(incs, intangible_assets):\n",
    "    for year in [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]:\n",
    "        missing_corp_data = {\"corp\": corp, \"year\": year, \"intangible_assets\": 0}\n",
    "        feature_intangible_assets = feature_intangible_assets.append(\n",
    "            missing_corp_data, ignore_index=True\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accounts Receivable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_receivable_ko_list = [\"매출채권\", \"매출채권 및 기타채권\", \"매출채권및기타채권\"]\n",
    "accounts_receivable_list = [\n",
    "    \"trade and other current receivables\",\n",
    "    \"trade and other receivables\",\n",
    "    \"short-term trade receivable\",\n",
    "    \"quick assets\",\n",
    "]\n",
    "\n",
    "accounts_receivable = bs[\n",
    "    (bs[\"label_en\"].isin(accounts_receivable_list))\n",
    "    | (bs[\"label_ko\"].isin(accounts_receivable_ko_list))\n",
    "]\n",
    "\n",
    "\n",
    "filtered_accounts_receivable = accounts_receivable.groupby(\n",
    "    \"corp\", group_keys=False\n",
    ").apply(custom_drop_logic)\n",
    "\n",
    "feature_accounts_receivable = process_feature(\n",
    "    filtered_accounts_receivable.copy(), \"accounts_receivable\"\n",
    ")\n",
    "\n",
    "find_missing_corps(bs, filtered_accounts_receivable)\n",
    "\n",
    "mask = feature_accounts_receivable[\"corp\"] == \"LG헬로비전\"\n",
    "feature_accounts_receivable.loc[mask] = feature_accounts_receivable.loc[mask].fillna(\n",
    "    151417834909\n",
    ")\n",
    "\n",
    "mask = (feature_accounts_receivable[\"corp\"] == \"디와이파워\") & (\n",
    "    feature_accounts_receivable[\"year\"] == \"2018\"\n",
    ")\n",
    "feature_accounts_receivable.loc[mask] = feature_accounts_receivable.loc[mask].fillna(\n",
    "    82570716535\n",
    ")\n",
    "\n",
    "mask = (feature_accounts_receivable[\"corp\"] == \"디와이파워\") & (\n",
    "    feature_accounts_receivable[\"year\"] == \"2019\"\n",
    ")\n",
    "feature_accounts_receivable.loc[mask] = feature_accounts_receivable.loc[mask].fillna(\n",
    "    68055002877\n",
    ")\n",
    "\n",
    "for corp in find_missing_corps(bs, accounts_receivable):\n",
    "    for year in [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]:\n",
    "        missing_corp_data = {\"corp\": corp, \"year\": year, \"accounts_receivable\": 0}\n",
    "        feature_accounts_receivable = feature_accounts_receivable.append(\n",
    "            missing_corp_data, ignore_index=True\n",
    "        )\n",
    "\n",
    "mask = (feature_accounts_receivable[\"corp\"] == \"에스케이바이오팜\") & (\n",
    "    feature_accounts_receivable[\"year\"] == \"2018\"\n",
    ")\n",
    "feature_accounts_receivable.loc[mask] = feature_accounts_receivable.loc[mask].fillna(0)\n",
    "\n",
    "mask = (feature_accounts_receivable[\"corp\"] == \"일성건설\") & (\n",
    "    feature_accounts_receivable[\"year\"] == \"2018\"\n",
    ")\n",
    "feature_accounts_receivable.loc[mask] = feature_accounts_receivable.loc[mask].fillna(\n",
    "    95565196656\n",
    ")\n",
    "\n",
    "mask = (feature_accounts_receivable[\"corp\"] == \"오리온홀딩스\") & (\n",
    "    feature_accounts_receivable[\"year\"] == \"2018\"\n",
    ")\n",
    "feature_accounts_receivable.loc[mask] = feature_accounts_receivable.loc[mask].fillna(\n",
    "    176440000000\n",
    ")\n",
    "\n",
    "mask = (feature_accounts_receivable[\"corp\"] == \"오리온홀딩스\") & (\n",
    "    feature_accounts_receivable[\"year\"] == \"2019\"\n",
    ")\n",
    "feature_accounts_receivable.loc[mask] = feature_accounts_receivable.loc[mask].fillna(\n",
    "    183420000000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories_list = [\"inventories\"]\n",
    "\n",
    "inventories = bs[bs[\"label_en\"].isin((inventories_list))]\n",
    "\n",
    "inventories = inventories.drop_duplicates(subset=\"corp\", keep=\"first\")\n",
    "\n",
    "inventories = process_feature(inventories.copy(), \"inventory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corps = list(find_missing_corps(bs, inventories))\n",
    "years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "\n",
    "data = []\n",
    "for corp in corps:\n",
    "    for year in years:\n",
    "        data.append({\"corp\": corp, \"year\": year, \"inventory\": 0})\n",
    "\n",
    "inventory_df = pd.DataFrame(data, columns=inventories.columns)\n",
    "\n",
    "feature_inventory = pd.concat([inventories, inventory_df], ignore_index=True)\n",
    "\n",
    "mask = (feature_inventory[\"corp\"] == \"남광토건\") & (feature_inventory[\"year\"] == \"2021\")\n",
    "feature_inventory.loc[mask] = feature_inventory.loc[mask].fillna(0)\n",
    "\n",
    "mask = (feature_inventory[\"corp\"] == \"남광토건\") & (feature_inventory[\"year\"] == \"2022\")\n",
    "feature_inventory.loc[mask] = feature_inventory.loc[mask].fillna(0)\n",
    "\n",
    "mask = (feature_inventory[\"corp\"] == \"쏘카\") & (feature_inventory[\"year\"] == \"2021\")\n",
    "feature_inventory.loc[mask] = feature_inventory.loc[mask].fillna(0)\n",
    "\n",
    "mask = (feature_inventory[\"corp\"] == \"쏘카\") & (feature_inventory[\"year\"] == \"2022\")\n",
    "feature_inventory.loc[mask] = feature_inventory.loc[mask].fillna(0)\n",
    "\n",
    "mask = (feature_inventory[\"corp\"] == \"아이에이치큐\") & (feature_inventory[\"year\"] == \"2022\")\n",
    "feature_inventory.loc[mask] = feature_inventory.loc[mask].fillna(1163920003)\n",
    "\n",
    "mask = (feature_inventory[\"corp\"] == \"키다리스튜디오\") & (feature_inventory[\"year\"] == \"2018\")\n",
    "feature_inventory.loc[mask] = feature_inventory.loc[mask].fillna(0)\n",
    "\n",
    "mask = (feature_inventory[\"corp\"] == \"한전산업\") & (feature_inventory[\"year\"] == \"2020\")\n",
    "feature_inventory.loc[mask] = feature_inventory.loc[mask].fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accounts Payable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_payable_ko_list = [\n",
    "    \"매입채무\",\n",
    "    \"매입채무 및 기타유동채무\",\n",
    "    \"매입채무 및 기타채무\",\n",
    "    \"단기매입채무\",\n",
    "    \"매입채무및기타채무\",\n",
    "    \"매입채무 및 기타금융부채\",\n",
    "]\n",
    "accounts_payable_list = [\n",
    "    \"trade and other current payables\",\n",
    "    \"trade and other payables\",\n",
    "    \"short-term trade payables\",\n",
    "    \"other accounts payable\",\n",
    "    \"account payables and other payables\",\n",
    "    \"long-term trade and other non-current payables\",\n",
    "    \"other current payables\",\n",
    "    \"other current financial liabilities\",\n",
    "]\n",
    "\n",
    "accounts_payable = bs[\n",
    "    (bs[\"label_en\"].isin(accounts_payable_list))\n",
    "    | (bs[\"label_ko\"].isin(accounts_payable_ko_list))\n",
    "]\n",
    "\n",
    "\n",
    "def custom_drop_logic(group):\n",
    "    null_counts = group.isnull().sum(axis=1)\n",
    "\n",
    "    return group.loc[null_counts.idxmin()]\n",
    "\n",
    "\n",
    "filtered_accounts_payable = accounts_payable.groupby(\"corp\", group_keys=False).apply(\n",
    "    custom_drop_logic\n",
    ")\n",
    "\n",
    "feature_accounts_payable = process_feature(\n",
    "    filtered_accounts_payable.copy(), \"accounts_payable\"\n",
    ")\n",
    "\n",
    "find_missing_corps(bs, filtered_accounts_payable)\n",
    "\n",
    "mask = (feature_accounts_payable[\"corp\"] == \"에스케이바이오팜\") & (\n",
    "    feature_accounts_payable[\"year\"] == \"2018\"\n",
    ")\n",
    "feature_accounts_payable.loc[mask] = feature_accounts_payable.loc[mask].fillna(0)\n",
    "\n",
    "mask = (feature_accounts_payable[\"corp\"] == \"에스케이바이오팜\") & (\n",
    "    feature_accounts_payable[\"year\"] == \"2019\"\n",
    ")\n",
    "feature_accounts_payable.loc[mask] = feature_accounts_payable.loc[mask].fillna(0)\n",
    "\n",
    "mask = (feature_accounts_payable[\"corp\"] == \"일성건설\") & (\n",
    "    feature_accounts_payable[\"year\"] == \"2018\"\n",
    ")\n",
    "feature_accounts_payable.loc[mask] = feature_accounts_payable.loc[mask].fillna(\n",
    "    38700000000\n",
    ")\n",
    "\n",
    "mask = (feature_accounts_payable[\"corp\"] == \"일성건설\") & (\n",
    "    feature_accounts_payable[\"year\"] == \"2018\"\n",
    ")\n",
    "feature_accounts_payable.loc[mask] = feature_accounts_payable.loc[mask].fillna(\n",
    "    38700000000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of shares outstanding\n",
    "- Whenever number of shares outstanding data is updated in DART API, use the crawling code below to get outstanding shares data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dart_fss as dart\n",
    "\n",
    "# api_key='58b7a0538b393d6c96f7f93b31101d5f407c9d1d'\n",
    "# dart.set_api_key(api_key=api_key)\n",
    "\n",
    "# corp_list = dart.get_corp_list()\n",
    "# kospi_list = corp_list.find_by_corp_name(corp_name='', market='Y')\n",
    "\n",
    "# successful_list = list(bs['corp'].unique())\n",
    "# kospi_list = [comp.corp_name for comp in kospi_list]\n",
    "# failed_list = [comp for comp in kospi_list if comp not in successful_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# corp_dict = {}\n",
    "\n",
    "# kospi_list\n",
    "\n",
    "# for comp in kospi_list:\n",
    "#     corp_dict[comp.corp_name] = comp.corp_code\n",
    "\n",
    "# for key in failed_list:\n",
    "#     if key in corp_dict:\n",
    "#         del corp_dict[key]\n",
    "\n",
    "# url = 'https://opendart.fss.or.kr/api/stockTotqySttus.json'\n",
    "# api_key = '58b7a0538b393d6c96f7f93b31101d5f407c9d1d'\n",
    "# years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for corp_name, corp_code in corp_dict.items():\n",
    "#     for year in years:\n",
    "#         params = {\n",
    "#             'crtfc_key': api_key,\n",
    "#             'corp_code': corp_code,\n",
    "#             'bsns_year': year,\n",
    "#             'reprt_code': '11011'\n",
    "#         }\n",
    "\n",
    "#         response = requests.get(url, params=params)\n",
    "\n",
    "#         if response.status_code == 200:\n",
    "#             data = response.json()\n",
    "\n",
    "#             total_outstanding_shares = 0\n",
    "#             for entry in data.get('list', []):\n",
    "#                 outstanding_shares = entry.get('istc_totqy', '0').replace(',', '')\n",
    "#                 if outstanding_shares.isdigit():\n",
    "#                     total_outstanding_shares += int(outstanding_shares)\n",
    "\n",
    "#             results.append({\n",
    "#                 'company_name': corp_name,\n",
    "#                 'year': year,\n",
    "#                 'total_outstanding_shares': total_outstanding_shares\n",
    "#             })\n",
    "\n",
    "#         else:\n",
    "#             print(f'Error: Unable to fetch data for {corp_name} in {year}. HTTP Status code: {response.status_code}')\n",
    "\n",
    "# df = pd.DataFrame(results)\n",
    "\n",
    "# df = df.pivot(index='company_name', columns='year', values='total_outstanding_shares')\n",
    "\n",
    "# df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/qrlg6jnd1l5b_xdkq486q0zr0000gn/T/ipykernel_11908/3066102631.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  outstanding_shares = pd.read_sql(query, cnx)\n"
     ]
    }
   ],
   "source": [
    "cnx = pymysql.connect(\n",
    "    user=\"*****\",\n",
    "    password=\"*****\",\n",
    "    host=\"ec2-15-152-211-160.ap-northeast-3.compute.amazonaws.com\",\n",
    "    database=\"Data_Lake\",\n",
    ")\n",
    "\n",
    "query = \"SELECT * FROM Data_Lake.outstanding_shares;\"\n",
    "outstanding_shares = pd.read_sql(query, cnx)\n",
    "cnx.close()\n",
    "\n",
    "corp_list = list(bs[\"corp\"].unique())\n",
    "\n",
    "outstanding_shares = (\n",
    "    outstanding_shares[outstanding_shares[\"company_name\"].isin(corp_list)]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "columns_to_convert = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    outstanding_shares[column] = (\n",
    "        outstanding_shares[column]\n",
    "        .str.replace(\",\", \"\")\n",
    "        .replace(\"-\", \"0\")\n",
    "        .fillna(\"0\")\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "# outstanding_shares = pd.read_csv(\"outstanding_shares.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_outstanding_shares = pd.melt(\n",
    "    outstanding_shares,\n",
    "    id_vars=[\"company_name\"],\n",
    "    var_name=\"year\",\n",
    "    value_name=\"outstanding_shares\",\n",
    ")\n",
    "feature_outstanding_shares = feature_outstanding_shares.rename(\n",
    "    columns={\"company_name\": \"corp\"}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash Flows from Operating Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfps_list = [\n",
    "    \"cash flows from (used in) operating activities\",\n",
    "    \"cash flows from operating activities\",\n",
    "    \"operating activity cash flow\",\n",
    "    \"net cash flows from operating activities\",\n",
    "    \"operating activities\",\n",
    "    \"i. cash flows from (used in) operating activities\",\n",
    "    \"cash flows provided by operating activities\",\n",
    "]\n",
    "\n",
    "cfps = cf[cf[\"label_en\"].isin((cfps_list))]\n",
    "\n",
    "filtered_cfps = cfps.groupby(\"corp\", group_keys=False).apply(custom_drop_logic)\n",
    "\n",
    "feature_cash_flow = process_feature(filtered_cfps.copy(), \"cash_flow_operating\")\n",
    "\n",
    "feature_cash_flow.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mask = feature_cash_flow[\"corp\"] == \"SK케미칼\"\n",
    "feature_cash_flow.loc[mask] = feature_cash_flow.loc[mask].fillna(122100000000)\n",
    "\n",
    "\n",
    "corps_names = [\"이마트\", \"인지컨트롤스\", \"동원산업\", \"삼성전기\", \"현대엘리베이터\"]\n",
    "years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "\n",
    "# NULL값 직접 채우기\n",
    "values_to_fill_by_company = [\n",
    "    [770000000000, 815700000000, 1386000000000, 987100000000, 745700000000],\n",
    "    [7800000000, 40500000000, 31700000000, 14900000000, 13800000000],\n",
    "    [53000000000, 193200000000, 402200000000, 587200000000, 499200000000],\n",
    "    [1558700000000, 1021200000000, 1588000000000, 1731200000000, 1575300000000],\n",
    "    [168600000000, 102000000000, 156100000000, 134300000000, -13500000000],\n",
    "]\n",
    "\n",
    "for corp_name, values_to_fill in zip(corps_names, values_to_fill_by_company):\n",
    "    for year, value in zip(years, values_to_fill):\n",
    "        mask = (feature_cash_flow[\"corp\"] == corp_name) & (\n",
    "            feature_cash_flow[\"year\"] == year\n",
    "        )\n",
    "        feature_cash_flow.loc[mask] = feature_cash_flow.loc[mask].fillna(value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selling, General & Administrative expenses (SG&A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sga_ko_list = [\"판매비와관리비\", \"관리비\", \"판매리와관리비\", \"판매비와 관리비\"]\n",
    "sga_list = [\n",
    "    \"selling general administrative expenses\",\n",
    "    \"administrative expenses\",\n",
    "    \"sales expenses\",\n",
    "    \"general administrative expenses\",\n",
    "    \"other cost of sales\",\n",
    "    \"elling expenses\",\n",
    "]\n",
    "\n",
    "sga = incs[(incs[\"label_en\"].isin(sga_list)) | (incs[\"label_ko\"].isin(sga_ko_list))]\n",
    "\n",
    "filtered_sga = sga.groupby(\"corp\", group_keys=False).apply(custom_drop_logic)\n",
    "\n",
    "feature_sga = process_feature(\n",
    "    filtered_sga.copy(), \"selling_general_administrative_expenses\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 없는 값 직접 채우기\n",
    "sga_data = {\n",
    "    \"AJ네트웍스\": [1066760000, 984610000, 850870000, 933880000, 1132920000],\n",
    "    \"CJ CGV\": [834630000, 1820300000, 972100000, 977760000, 1358070000],\n",
    "    \"KTcs\": [1003620000, 933520000, 913840000, 944680000, 1005140000],\n",
    "    \"LG헬로비전\": [993900000, 992960000, 934340000, 927220000, 938620000],\n",
    "    \"LX홀딩스\": [np.nan, np.nan, np.nan, 30220000000, 39890000000],\n",
    "    \"NAVER\": [4644370000, 3201210000, 4088800000, 5492120000, 6915410000],\n",
    "    \"NICE\": [1315630000, 1720010000, 1902370000, 2305600000, 2607680000],\n",
    "    \"SK디앤디\": [56280000, 49730000, 85500000, 671970000, 499090000],\n",
    "    \"SK렌터카\": [630680000, 467690000, 578120000, 750200000, 903990000],\n",
    "    \"SK텔레콤\": [15672200000, 16632540000, 14839170000, 15361420000, 15692900000],\n",
    "    \"넷마블\": [1779620000, 1976030000, 2212720000, 2355880000, 2782100000],\n",
    "    \"대구백화점\": [138370000, 115720000, 108660000, 99870000, 92200000],\n",
    "    \"도화엔지니어링\": [385180000, 489060000, 550910000, 557410000, 543880000],\n",
    "    \"롯데관광개발\": [28900000, 38960000, 88150000, 238320000, 302390000],\n",
    "    \"롯데렌탈\": [1753900000, 1924680000, 2092120000, 2177160000, 2430550000],\n",
    "    \"모두투어리츠\": [25300000, 29300000, 26100000, 27400000, 27400000],\n",
    "    \"쏘카\": [192550000, 328270000, 286150000, 309970000, 388040000],\n",
    "    \"에이플러스에셋\": [184000000, 248490000, 261980000, 124680000, 134480000],\n",
    "    \"엔씨소프트\": [1100190000, 1222190000, 1591390000, 1931740000, 2007790000],\n",
    "    \"엔에이치엔\": [1195930000, 1401920000, 1555500000, 1825810000, 2075820000],\n",
    "    \"카카오페이\": [166030000, 206410000, 302280000, 485870000, 567190000],\n",
    "    \"케이탑리츠\": [38200000, 38800000, 42000000, 139800000, 40900000],\n",
    "    \"케이티\": [22198620000, 23182500000, 22732560000, 23226180000, 23959920000],\n",
    "    \"케이티스카이라이프\": [624090000, 625280000, 624870000, 690200000, 971040000],\n",
    "    \"크라운해태홀딩스\": [327540000, 262330000, 268290000, 259080000, 258510000],\n",
    "    \"크래프톤\": [819780000, 728180000, 896560000, 1234740000, 1102410000],\n",
    "    \"풀무원\": [518780000, 559450000, 565520000, 617720000, 674090000],\n",
    "    \"하나투어\": [803400000, 607140000, 224440000, 167550000, 216150000],\n",
    "    \"한미사이언스\": [697000000, 800470000, 832230000, 921410000, 1017940000],\n",
    "    \"호텔신라\": [2042420000, 2120770000, 1280660000, 1603900000, 2682580000],\n",
    "}\n",
    "\n",
    "years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "\n",
    "values_list = []\n",
    "for corp, values in sga_data.items():\n",
    "    for year, value in zip(years, values):\n",
    "        values_list.append(\n",
    "            {\n",
    "                \"corp\": corp,\n",
    "                \"year\": year,\n",
    "                \"selling_general_administrative_expenses\": value,\n",
    "            }\n",
    "        )\n",
    "\n",
    "feature_sga_to_append = pd.DataFrame(values_list)\n",
    "\n",
    "feature_sga = feature_sga.append(feature_sga_to_append)\n",
    "\n",
    "feature_sga.loc[\n",
    "    (feature_sga[\"corp\"] == \"LG유플러스\") & (feature_sga[\"year\"] == \"2018\"),\n",
    "    \"selling_general_administrative_expenses\",\n",
    "] = 10984920000000\n",
    "feature_sga.loc[\n",
    "    (feature_sga[\"corp\"] == \"LG유플러스\") & (feature_sga[\"year\"] == \"2019\"),\n",
    "    \"selling_general_administrative_expenses\",\n",
    "] = 11695730000000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash Flows from Investing Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_flow_investing_ko_list = [\n",
    "    \"투자활동 현금흐름\",\n",
    "    \"투자활동현금흐름\",\n",
    "    \"투자활동으로 인한 현금흐름\",\n",
    "    \"II. 투자활동현금흐름\",\n",
    "]\n",
    "cash_flow_investing_list = [\n",
    "    \"cash flows from investing activities\",\n",
    "    \"cash flows from (used in) investing activities\",\n",
    "    \"investing activities\",\n",
    "    \"cash flows from (used in) investing activities.\",\n",
    "]\n",
    "\n",
    "cash_flow_investing = cf[\n",
    "    (cf[\"label_en\"].isin(cash_flow_investing_list))\n",
    "    | (cf[\"label_ko\"].isin(cash_flow_investing_ko_list))\n",
    "]\n",
    "\n",
    "filtered_cash_flow_investing = cash_flow_investing.groupby(\n",
    "    \"corp\", group_keys=False\n",
    ").apply(custom_drop_logic)\n",
    "\n",
    "feature_cash_flow_investing = process_feature(\n",
    "    filtered_cash_flow_investing.copy(), \"cash_flow_investing\"\n",
    ")\n",
    "\n",
    "update_values = {\n",
    "    \"SK케미칼\": {\"2019\": -1007.5},\n",
    "    \"제주항공\": {\"2018\": -63.2},\n",
    "    \"동원산업\": {\n",
    "        \"2018\": -663.4,\n",
    "        \"2019\": -499.6,\n",
    "        \"2020\": -1305.2,\n",
    "        \"2021\": -4775.6,\n",
    "        \"2022\": 66.4,\n",
    "    },\n",
    "    \"이마트\": {\n",
    "        \"2018\": -8167.8,\n",
    "        \"2019\": -10050.8,\n",
    "        \"2020\": -783.1,\n",
    "        \"2021\": -39012.2,\n",
    "        \"2022\": -7143.7,\n",
    "    },\n",
    "    \"인지컨트롤스\": {\n",
    "        \"2018\": -317.0,\n",
    "        \"2019\": -709.7,\n",
    "        \"2020\": -318.1,\n",
    "        \"2021\": -321.5,\n",
    "        \"2022\": -388.1,\n",
    "    },\n",
    "    \"현대엘리베이터\": {\n",
    "        \"2018\": -1364.4,\n",
    "        \"2019\": -3475.7,\n",
    "        \"2020\": 576.3,\n",
    "        \"2021\": -2806.3,\n",
    "        \"2022\": -1553.3,\n",
    "    },\n",
    "}\n",
    "\n",
    "conversion_factor = 100000000\n",
    "\n",
    "for corp, years in update_values.items():\n",
    "    for year, value in years.items():\n",
    "        adjusted_value = value * conversion_factor\n",
    "        feature_cash_flow_investing.loc[\n",
    "            (feature_cash_flow_investing[\"corp\"] == corp)\n",
    "            & (feature_cash_flow_investing[\"year\"] == year),\n",
    "            \"cash_flow_investing\",\n",
    "        ] = adjusted_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash Flows from Financing Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_flow_financing_ko_list = [\n",
    "    \"재무활동 현금흐름\",\n",
    "    \"III. 재무활동현금흐름\",\n",
    "    \"재무활동으로 인한 현금흐름\",\n",
    "    \"재무활동현금흐름\",\n",
    "]\n",
    "cash_flow_financing_list = [\n",
    "    \"cash flows from financing activities\",\n",
    "    \"cash flows from (used in) financing activities.\",\n",
    "    \"cash flows from (used in) financing activities\",\n",
    "]\n",
    "\n",
    "cash_flow_financing = cf[\n",
    "    (cf[\"label_en\"].isin(cash_flow_financing_list))\n",
    "    | (cf[\"label_ko\"].isin(cash_flow_financing_ko_list))\n",
    "]\n",
    "\n",
    "filtered_cash_flow_financing = cash_flow_financing.groupby(\n",
    "    \"corp\", group_keys=False\n",
    ").apply(custom_drop_logic)\n",
    "\n",
    "feature_cash_flow_financing = process_feature(\n",
    "    filtered_cash_flow_financing.copy(), \"cash_flow_financing\"\n",
    ")\n",
    "\n",
    "update_values = {\n",
    "    \"SK케미칼\": {\"2019\": 1171.5},\n",
    "    \"동원산업\": {\n",
    "        \"2018\": -897.9,\n",
    "        \"2019\": -900.2,\n",
    "        \"2020\": -2129.5,\n",
    "        \"2021\": -879.5,\n",
    "        \"2022\": -2868.5,\n",
    "    },\n",
    "    \"삼성전기\": {\"2020\": -2094.7, \"2021\": -11809.7, \"2022\": 1930.6},\n",
    "    \"이마트\": {\n",
    "        \"2018\": 1028.5,\n",
    "        \"2019\": 5810.2,\n",
    "        \"2020\": -8700.8,\n",
    "        \"2021\": 27904.3,\n",
    "        \"2022\": 2219.2,\n",
    "    },\n",
    "    \"인지컨트롤스\": {\"2018\": 62.5, \"2019\": 368.1, \"2020\": 10.4, \"2021\": 124.0, \"2022\": 156.9},\n",
    "    \"현대엘리베이터\": {\n",
    "        \"2018\": -172.9,\n",
    "        \"2019\": 1682.2,\n",
    "        \"2020\": -372.0,\n",
    "        \"2021\": 659.5,\n",
    "        \"2022\": -51.1,\n",
    "    },\n",
    "}\n",
    "\n",
    "conversion_factor = 100000000\n",
    "\n",
    "for corp, years in update_values.items():\n",
    "    for year, value in years.items():\n",
    "        adjusted_value = value * conversion_factor\n",
    "        feature_cash_flow_financing.loc[\n",
    "            (feature_cash_flow_financing[\"corp\"] == corp)\n",
    "            & (feature_cash_flow_financing[\"year\"] == year),\n",
    "            \"cash_flow_financing\",\n",
    "        ] = adjusted_value\n",
    "\n",
    "mask = (feature_cash_flow_financing[\"corp\"] == \"한올바이오파마\") & (\n",
    "    feature_cash_flow_financing[\"year\"] == \"2018\"\n",
    ")\n",
    "feature_cash_flow_financing.loc[\n",
    "    mask, \"cash_flow_financing\"\n",
    "] = feature_cash_flow_financing.loc[mask, \"cash_flow_financing\"].fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long-term assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_term_assets_ko_list = []\n",
    "long_term_assets_list = [\"non-current assets\"]\n",
    "\n",
    "long_term_assets = bs[\n",
    "    (bs[\"label_en\"].isin(long_term_assets_list))\n",
    "    | (bs[\"label_ko\"].isin(long_term_assets_ko_list))\n",
    "]\n",
    "\n",
    "filtered_long_term_assets = long_term_assets.groupby(\"corp\", group_keys=False).apply(\n",
    "    custom_drop_logic\n",
    ")\n",
    "\n",
    "feature_long_term_assets = process_feature(\n",
    "    filtered_long_term_assets.copy(), \"long_term_assets\"\n",
    ")\n",
    "\n",
    "feature_long_term_assets[feature_long_term_assets[\"corp\"] == \"마니커\"]\n",
    "\n",
    "values_by_year = {\n",
    "    \"2019\": 152940000000,\n",
    "    \"2020\": 145860000000,\n",
    "    \"2021\": 126680000000,\n",
    "    \"2022\": 107520000000,\n",
    "}\n",
    "\n",
    "for year, value in values_by_year.items():\n",
    "    mask = (feature_long_term_assets[\"corp\"] == \"마니커\") & (\n",
    "        feature_long_term_assets[\"year\"] == year\n",
    "    )\n",
    "    feature_long_term_assets.loc[mask, \"long_term_assets\"] = value\n",
    "\n",
    "\n",
    "values_by_year = {\n",
    "    \"2018\": 56440000000,\n",
    "    \"2019\": 57630000000,\n",
    "    \"2020\": 49520000000,\n",
    "    \"2021\": 53840000000,\n",
    "    \"2022\": 63220000000,\n",
    "}\n",
    "\n",
    "for year, value in values_by_year.items():\n",
    "    mask = (feature_long_term_assets[\"corp\"] == \"아남전자\") & (\n",
    "        feature_long_term_assets[\"year\"] == year\n",
    "    )\n",
    "    feature_long_term_assets.loc[mask, \"long_term_assets\"] = value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_ko_list = [\"금융비용\", \"금융원가\", \"순금융수익(원가)\"]\n",
    "interest_list = [\n",
    "    \"finance costs\",\n",
    "    \"financail costs\",\n",
    "    \"financial expenses\",\n",
    "    \"net finance income(cost)\",\n",
    "]\n",
    "\n",
    "interest = incs[\n",
    "    (incs[\"label_en\"].isin(interest_list)) | (incs[\"label_ko\"].isin(interest_ko_list))\n",
    "]\n",
    "\n",
    "filtered_interest = interest.groupby(\"corp\", group_keys=False).apply(custom_drop_logic)\n",
    "\n",
    "feature_interest = process_feature(filtered_interest.copy(), \"interest\")\n",
    "\n",
    "mask = (feature_interest[\"corp\"] == \"동원산업\") & (feature_interest[\"year\"] == \"2018\")\n",
    "feature_interest.loc[mask] = feature_interest.loc[mask].fillna(35080000000)\n",
    "\n",
    "mask = (feature_interest[\"corp\"] == \"동원산업\") & (feature_interest[\"year\"] == \"2019\")\n",
    "feature_interest.loc[mask] = feature_interest.loc[mask].fillna(48170000000)\n",
    "\n",
    "mask = (feature_interest[\"corp\"] == \"동원산업\") & (feature_interest[\"year\"] == \"2020\")\n",
    "feature_interest.loc[mask, \"interest\"] = 44520000000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_ko_list = [\n",
    "    \"법인세납부\",\n",
    "    \"법인세의 환급(납부)\",\n",
    "    \"법인세의 납부\",\n",
    "    \"법인세환급(납부)\",\n",
    "    \"법인세의 납부(환급)\",\n",
    "    \"법인세 납부액\",\n",
    "    \"(3) 법인세환급(납부)\",\n",
    "    \"4. 법인세의 납부\",\n",
    "    \"법인세 환급(납부)\",\n",
    "    \"법인세 부담액\",\n",
    "    \"법인세 지급액\",\n",
    "    \"법인세 환급액(납부액)\",\n",
    "    \"법인세의 지급\",\n",
    "    \"법인세의납부\",\n",
    "    \"법인세의 환급\",\n",
    "]\n",
    "tax_list = [\n",
    "    \"income taxes paid (refund)\",\n",
    "    \"income taxes paid classified as operating activities\",\n",
    "    \"income taxes paid\",\n",
    "    \"income taxes paid2\",\n",
    "    \"income taxes refund (paid)\",\n",
    "    \"income taxes refund(paid)\",\n",
    "]\n",
    "\n",
    "tax = cf[(cf[\"label_en\"].isin(tax_list)) | (cf[\"label_ko\"].isin(tax_ko_list))]\n",
    "\n",
    "filtered_tax = tax.groupby(\"corp\", group_keys=False).apply(custom_drop_logic)\n",
    "\n",
    "feature_tax = process_feature(filtered_tax.copy(), \"tax\")\n",
    "\n",
    "values_by_year = {\n",
    "    \"2018\": -15930000000,\n",
    "    \"2019\": 2310000000,\n",
    "    \"2020\": -19980000000,\n",
    "    \"2021\": -23920000000,\n",
    "    \"2022\": -24140000000,\n",
    "}\n",
    "\n",
    "data_to_append = []\n",
    "\n",
    "for year, value in values_by_year.items():\n",
    "    row = {\"corp\": \"한화시스템\", \"year\": year, \"tax\": value}\n",
    "    data_to_append.append(row)\n",
    "\n",
    "hanhwa_data = pd.DataFrame(data_to_append)\n",
    "\n",
    "feature_tax = feature_tax.append(hanhwa_data, ignore_index=True)\n",
    "\n",
    "feature_tax.loc[feature_tax[\"corp\"] == \"KG모빌리티\", \"tax\"] = feature_tax.loc[\n",
    "    feature_tax[\"corp\"] == \"KG모빌리티\", \"tax\"\n",
    "].fillna(0)\n",
    "\n",
    "mask = (feature_tax[\"corp\"] == \"대웅제약\") & (feature_tax[\"year\"] == \"2018\")\n",
    "feature_tax.loc[mask, \"tax\"] = feature_tax.loc[mask, \"tax\"].fillna(-7910000000)\n",
    "\n",
    "mask = (feature_tax[\"corp\"] == \"대웅제약\") & (feature_tax[\"year\"] == \"2019\")\n",
    "feature_tax.loc[mask, \"tax\"] = feature_tax.loc[mask, \"tax\"].fillna(-22300000000)\n",
    "\n",
    "mask = (feature_tax[\"corp\"] == \"보해양조\") & (feature_tax[\"year\"] == \"2019\")\n",
    "feature_tax.loc[mask, \"tax\"] = feature_tax.loc[mask, \"tax\"].fillna(0)\n",
    "\n",
    "mask = (feature_tax[\"corp\"] == \"삼부토건\") & (feature_tax[\"year\"] == \"2018\")\n",
    "feature_tax.loc[mask, \"tax\"] = feature_tax.loc[mask, \"tax\"].fillna(0)\n",
    "\n",
    "mask = (feature_tax[\"corp\"] == \"삼영\") & (feature_tax[\"year\"] == \"2018\")\n",
    "feature_tax.loc[mask, \"tax\"] = feature_tax.loc[mask, \"tax\"].fillna(0)\n",
    "\n",
    "mask = (feature_tax[\"corp\"] == \"삼영\") & (feature_tax[\"year\"] == \"2019\")\n",
    "feature_tax.loc[mask, \"tax\"] = feature_tax.loc[mask, \"tax\"].fillna(0)\n",
    "\n",
    "mask = (feature_tax[\"corp\"] == \"써니전자\") & (feature_tax[\"year\"] == \"2018\")\n",
    "feature_tax.loc[mask, \"tax\"] = feature_tax.loc[mask, \"tax\"].fillna(0)\n",
    "\n",
    "mask = (feature_tax[\"corp\"] == \"티웨이항공\") & (feature_tax[\"year\"] == \"2022\")\n",
    "feature_tax.loc[mask, \"tax\"] = feature_tax.loc[mask, \"tax\"].fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/qrlg6jnd1l5b_xdkq486q0zr0000gn/T/ipykernel_5137/1500691239.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, cnx)\n"
     ]
    }
   ],
   "source": [
    "cnx = pymysql.connect(\n",
    "    user=\"*****\",\n",
    "    password=\"*****\",\n",
    "    host=\"ec2-15-152-211-160.ap-northeast-3.compute.amazonaws.com\",\n",
    "    database=\"Data_Lake\",\n",
    ")\n",
    "\n",
    "query = \"SELECT * FROM Data_Lake.stock_data_per_month;\"\n",
    "data = pd.read_sql(query, cnx)\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_list = list(bs[\"corp\"].unique())\n",
    "\n",
    "data = data[data[\"corp\"].isin(corp_list)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "\n",
    "idx = data.groupby([data[\"corp\"], data[\"date\"].dt.year])[\"date\"].idxmax()\n",
    "\n",
    "stock_data = data.loc[idx]\n",
    "\n",
    "stock_data[\"year\"] = stock_data[\"date\"].dt.year\n",
    "\n",
    "stock_data = stock_data[(stock_data[\"year\"] >= 2018) & (stock_data[\"year\"] <= 2022)]\n",
    "\n",
    "stock_data = (\n",
    "    stock_data[[\"corp\", \"year\", \"close\"]]\n",
    "    .rename(columns={\"close\": \"stock_price\"})\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "feature_stock_price = stock_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_years = set(range(2018, 2023))\n",
    "\n",
    "for corp in corp_list:\n",
    "    present_years = set(\n",
    "        feature_stock_price[feature_stock_price[\"corp\"] == corp][\"year\"]\n",
    "    )\n",
    "\n",
    "    missing_years = required_years - present_years\n",
    "\n",
    "    for missing_year in missing_years:\n",
    "        feature_stock_price = feature_stock_price.append(\n",
    "            {\"corp\": corp, \"year\": missing_year, \"stock_price\": np.nan},\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "feature_stock_price = feature_stock_price.sort_values(by=[\"corp\", \"year\"]).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "feature_stock_price[\"year\"] = feature_stock_price[\"year\"].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(\n",
    "    feature_stock_price, feature_outstanding_shares, on=[\"corp\", \"year\"]\n",
    ")\n",
    "\n",
    "merged_data[\"market_capitalization\"] = (\n",
    "    merged_data[\"stock_price\"] * merged_data[\"outstanding_shares\"]\n",
    ")\n",
    "\n",
    "feature_market_capitalization = merged_data[[\"corp\", \"year\", \"market_capitalization\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Features and preprocess initial features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3265, 34)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = [\n",
    "    feature_revenue,\n",
    "    feature_cost_of_sales,\n",
    "    feature_gross_profit,\n",
    "    feature_operating_income,\n",
    "    feature_net_income,\n",
    "    feature_ebit,\n",
    "    feature_ebitda,\n",
    "    feature_total_equity,\n",
    "    feature_total_assets,\n",
    "    feature_total_liabilities,\n",
    "    feature_current_assets,\n",
    "    feature_current_liabilities,\n",
    "    feature_non_current_liabilities,\n",
    "    feature_short_borrowing,\n",
    "    feature_long_borrowing,\n",
    "    feature_cash_and_equivalents,\n",
    "    feature_retained_earnings,\n",
    "    feature_tangible_assets,\n",
    "    feature_intangible_assets,\n",
    "    feature_accounts_receivable,\n",
    "    feature_inventory,\n",
    "    feature_accounts_payable,\n",
    "    feature_outstanding_shares,\n",
    "    feature_cash_flow,\n",
    "    feature_sga,\n",
    "    feature_cash_flow_investing,\n",
    "    feature_cash_flow_financing,\n",
    "    feature_long_term_assets,\n",
    "    feature_interest,\n",
    "    feature_tax,\n",
    "    feature_stock_price,\n",
    "    feature_market_capitalization,\n",
    "]\n",
    "\n",
    "feature_combined = feature_list[0]\n",
    "\n",
    "for feature_df in feature_list[1:]:\n",
    "    feature_combined = pd.merge(feature_combined, feature_df, on=[\"corp\", \"year\"])\n",
    "\n",
    "feature_combined.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "feature_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_remove_daeduk = feature_combined[\"corp\"] != \"대덕\"\n",
    "feature_combined = feature_combined[mask_remove_daeduk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/qrlg6jnd1l5b_xdkq486q0zr0000gn/T/ipykernel_5137/1568199681.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  feature_combined = feature_combined[~mask_rows_with_many_nulls]\n"
     ]
    }
   ],
   "source": [
    "mask_rows_with_many_nulls = feature_combined.isnull().sum(axis=1) >= 5\n",
    "mask_year_is_2022 = feature_combined[\"year\"] == \"2022\"\n",
    "combined_mask = mask_rows_with_many_nulls & mask_year_is_2022\n",
    "remove_corps = feature_combined[combined_mask]\n",
    "\n",
    "remove_corps_list = remove_corps[\"corp\"].unique()\n",
    "\n",
    "mask_corps_to_exclude = feature_combined[\"corp\"].isin(remove_corps_list)\n",
    "\n",
    "feature_combined = feature_combined[~mask_corps_to_exclude]\n",
    "\n",
    "feature_combined = feature_combined[~mask_rows_with_many_nulls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3104, 34)\n",
      "(39, 34)\n"
     ]
    }
   ],
   "source": [
    "print(feature_combined.shape)\n",
    "null_rows = feature_combined[feature_combined.isnull().any(axis=1)]\n",
    "print(null_rows.shape)\n",
    "# null_rows.to_csv(\"null.csv\", encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement operations on some of the initial features before implementing new features for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_combined[\"borrowings\"] = (\n",
    "    feature_combined[\"short_borrowing\"] + feature_combined[\"long_borrowing\"]\n",
    ")\n",
    "\n",
    "feature_combined[\"net_liabilities\"] = (\n",
    "    feature_combined[\"total_liabilities\"] - feature_combined[\"cash_and_equivalents\"]\n",
    ")\n",
    "\n",
    "feature_combined[\"fixed_assets\"] = (\n",
    "    feature_combined[\"tangible_assets\"] + feature_combined[\"intangible_assets\"]\n",
    ")\n",
    "\n",
    "feature_combined[\"cash_flow_per_share\"] = (\n",
    "    feature_combined[\"cash_flow_operating\"] / feature_combined[\"outstanding_shares\"]\n",
    ")\n",
    "\n",
    "feature_combined[\"cash_flow_per_share\"].replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add stock_code & sector next to corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_sector_df = pd.read_csv(\"sector.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "corp_stock_code_dict = {\n",
    "    row[\"corp\"]: str(row[\"stock_code\"]).zfill(6) for index, row in bs.iterrows()\n",
    "}\n",
    "corp_sector_dict = {\n",
    "    str(row[\"종목코드\"]).zfill(6): row[\"업종명\"] for index, row in corp_sector_df.iterrows()\n",
    "}\n",
    "\n",
    "\n",
    "def get_sector(stock_code):\n",
    "    return corp_sector_dict.get(stock_code)\n",
    "\n",
    "\n",
    "feature_combined[\"stock_code\"] = feature_combined[\"corp\"].apply(\n",
    "    lambda x: corp_stock_code_dict.get(x, None)\n",
    ")\n",
    "feature_combined[\"sector\"] = feature_combined[\"stock_code\"].apply(get_sector)\n",
    "\n",
    "columns = list(feature_combined.columns)\n",
    "ordered_columns = [columns[0]] + [\"stock_code\", \"sector\"] + columns[1:-2]\n",
    "feature_combined = feature_combined[ordered_columns]\n",
    "\n",
    "# Add kospi data to MySQL\n",
    "kospi = corp_sector_df[[\"종목코드\", \"종목명\", \"시장구분\", \"업종명\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3104, 40)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_combined.to_csv(\"preprocessed.csv\", encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature_combined & kospi to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "username = \"*****\"\n",
    "password = \"*****\"\n",
    "hostname = \"ec2-15-152-211-160.ap-northeast-3.compute.amazonaws.com\"\n",
    "database_name = \"Data_Warehouse\"\n",
    "\n",
    "desired_table_name = \"preprocessed\"\n",
    "\n",
    "cnx = pymysql.connect(user=username, password=password, host=hostname)\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "engine = create_engine(\n",
    "    \"mysql+pymysql://{user}:{pw}@{host}/{db}\".format(\n",
    "        user=username, pw=password, db=database_name, host=hostname\n",
    "    )\n",
    ")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "try:\n",
    "    feature_combined.to_sql(\n",
    "        desired_table_name, con=engine, if_exists=\"replace\", index=False, chunksize=1000\n",
    "    )\n",
    "    session.commit()\n",
    "except:\n",
    "    session.rollback()\n",
    "    raise\n",
    "finally:\n",
    "    session.close()\n",
    "\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ★ Extracted relevant information from Balance Sheet, Income Statement, Cash Flow Statement and preprocessed all the relevant info ★"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
